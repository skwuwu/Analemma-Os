# ğŸ—ï¸ Step Functions ì•„í‚¤í…ì²˜ ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“‹ ëª©ì°¨
1. [ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”](#1-ì „ì²´-ì•„í‚¤í…ì²˜-ê°œìš”)
2. [ìƒíƒœ ë¨¸ì‹  í”Œë¡œìš° ë¶„ì„](#2-ìƒíƒœ-ë¨¸ì‹ -í”Œë¡œìš°-ë¶„ì„)
3. [Lambda í•¨ìˆ˜ ìŠ¤í‚¤ë§ˆ ë§¤í•‘](#3-lambda-í•¨ìˆ˜-ìŠ¤í‚¤ë§ˆ-ë§¤í•‘)
4. [ë°ì´í„° íë¦„ ë° ì˜ì¡´ì„±](#4-ë°ì´í„°-íë¦„-ë°-ì˜ì¡´ì„±)
5. [ì„¸ê·¸ë¨¼íŠ¸í™” ë¡œì§ ë¶„ì„](#5-ì„¸ê·¸ë¨¼íŠ¸í™”-ë¡œì§-ë¶„ì„)
6. [ë¬¸ì œì  ë° ë¦¬íŒ©í† ë§ ê¶Œì¥ì‚¬í•­](#6-ë¬¸ì œì -ë°-ë¦¬íŒ©í† ë§-ê¶Œì¥ì‚¬í•­)

---

## 1. ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”

### 1.1 ì‹¤í–‰ ëª¨ë“œ
ì›Œí¬í”Œë¡œìš°ëŠ” 3ê°€ì§€ ì‹¤í–‰ ì „ëµì„ ì§€ì›í•©ë‹ˆë‹¤:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SelectDistributedStrategy                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                     â”‚
   MAP_REDUCE              BATCHED               SEQUENTIAL
   (ê³ ë™ì‹œì„±)              (ì¤‘ë™ì‹œì„±)              (ìˆœì°¨ì‹¤í–‰)
        â”‚                       â”‚                     â”‚
        â†“                       â†“                     â†“
ExecuteMapReduceMode    ExecuteBatchedMode    ExecuteSegment
  (Map State)           (Map State)           (Loop)
        â”‚                       â”‚                     â”‚
        â†“                       â†“                     â†“
AggregateMapReduce     AggregateBatched      PrepareNextSegment
    Results                Results              (ì¬ê·€ ë£¨í”„)
```

### 1.2 ìƒíƒœ ì „í™˜ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
stateDiagram-v2
    [*] --> CheckForInjectedConfig
    
    CheckForInjectedConfig --> InitializeStateData: MOCK_MODE
    CheckForInjectedConfig --> CheckForExistingExecution: Production
    
    CheckForExistingExecution --> HandleExistingExecution
    HandleExistingExecution --> FailDuplicateExecution: RUNNING
    HandleExistingExecution --> SucceedDuplicateExecution: SUCCEEDED
    HandleExistingExecution --> InitializeStateData: New
    
    InitializeStateData --> NotifyWorkflowStarted
    NotifyWorkflowStarted --> SelectDistributedStrategy
    
    SelectDistributedStrategy --> ExecuteMapReduceMode: MAP_REDUCE
    SelectDistributedStrategy --> ExecuteBatchedMode: BATCHED
    SelectDistributedStrategy --> ExecuteSegment: SEQUENTIAL
    
    ExecuteSegment --> CheckSegmentStatus
    
    CheckSegmentStatus --> COMPLETE: Complete
    CheckSegmentStatus --> PrepareNextSegment: CONTINUE
    CheckSegmentStatus --> ProcessParallelSegments: PARALLEL_GROUP
    CheckSegmentStatus --> WaitForCallback: PAUSE/HITP
    CheckSegmentStatus --> NotifyExecutionFailure: FAILED
    
    ProcessParallelSegments --> AggregateParallelResults
    AggregateParallelResults --> UpdateStateData
    
    PrepareNextSegment --> UpdateSegmentToRun
    UpdateSegmentToRun --> CheckLoopLimit
    CheckLoopLimit --> ExecuteSegment: Continue
    CheckLoopLimit --> LoopLimitExceeded: Limit Hit
    
    WaitForCallback --> PrepareStateAfterPause
    PrepareStateAfterPause --> ExecuteSegment
    
    COMPLETE --> PublishSucceededEvent
    PublishSucceededEvent --> WorkflowSucceeded
    WorkflowSucceeded --> [*]
```

---

## 2. ìƒíƒœ ë¨¸ì‹  í”Œë¡œìš° ë¶„ì„

### 2.1 ìƒíƒœ ë¶„ë¥˜

#### **Choice ìƒíƒœ (16ê°œ)**
| ìƒíƒœëª… | ëª©ì  | ë‹¤ìŒ ìƒíƒœ |
|--------|------|-----------|
| `CheckForInjectedConfig` | MOCK_MODE ì²´í¬ | InitializeStateData / CheckForExistingExecution |
| `HandleIdempotencyFailure` | ë©±ë“±ì„± ì‹¤íŒ¨ ì²˜ë¦¬ | InitializeStateData / FailIdempotencyUnavailable |
| `HandleExistingExecution` | ì¤‘ë³µ ì‹¤í–‰ ì²˜ë¦¬ | FailDuplicateExecution / SucceedDuplicateExecution / InitializeStateData |
| `CheckLargeWorkflow` | ëŒ€í˜• ì›Œí¬í”Œë¡œìš° ê²½ê³  | NotifyLargeWorkflowWarning / NotifyWorkflowStarted |
| `SelectDistributedStrategy` | ì‹¤í–‰ ì „ëµ ì„ íƒ | ExecuteMapReduceMode / ExecuteBatchedMode / ExecuteSegment |
| `CheckSegmentStatus` | ì„¸ê·¸ë¨¼íŠ¸ ìƒíƒœ í™•ì¸ | 12ê°œ ë¶„ê¸° (CONTINUE, PARALLEL_GROUP, PAUSE, FAILED ë“±) |
| `PrepareNextSegment` | ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ì¤€ë¹„ | UpdateSegmentToRun / PublishSucceededEvent |
| `IsPauseNeeded` | HITP ì¼ì‹œì •ì§€ í•„ìš” | WaitForCallback / CheckForNextSegment |
| `CheckForNextSegment` | ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ì¡´ì¬ í™•ì¸ | PrepareNextSegment / PublishSucceededEvent |
| `CheckLoopLimit` | ë¬´í•œë£¨í”„ ë°©ì§€ | ExecuteSegment / LoopLimitExceeded |
| `CheckIfAsyncRequired` | ë¹„ë™ê¸° LLM í•„ìš” | NotifyAsyncLLMProcessing / NotifyExecutionFailure |
| `CheckBranchNext` (Iterator ë‚´ë¶€) | ë¸Œëœì¹˜ ê³„ì† ì‹¤í–‰ í™•ì¸ | BranchComplete / UpdateBranchSegment / HandleBranchFailedStatus |
| `CheckBranchLoopLimit` (Iterator ë‚´ë¶€) | ë¸Œëœì¹˜ ë£¨í”„ ì œí•œ | ExecuteBranchSegment / BranchLoopLimitExceeded |

#### **Task ìƒíƒœ (21ê°œ)**

##### **Lambda í˜¸ì¶œ (11ê°œ)**
| ìƒíƒœëª… | Lambda í•¨ìˆ˜ | ìš©ë„ |
|--------|-------------|------|
| `InitializeStateData` | InitializeStateDataFunction | ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”, S3 ê²½ë¡œ ìƒì„±, íŒŒí‹°ì…˜ ë¡œë”© |
| `ExecuteSegment` | SegmentRunnerFunction | ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ ì‹¤í–‰ (SEQUENTIAL ëª¨ë“œ) |
| `MapReduceSegmentRunner` | SegmentRunnerFunction | Map-Reduce ëª¨ë“œ ì„¸ê·¸ë¨¼íŠ¸ ì‹¤í–‰ |
| `BatchedSegmentRunner` | SegmentRunnerFunction | Batched ëª¨ë“œ ì„¸ê·¸ë¨¼íŠ¸ ì‹¤í–‰ |
| `ExecuteBranchSegment` | SegmentRunnerFunction | ë³‘ë ¬ ë¸Œëœì¹˜ ë‚´ë¶€ ì„¸ê·¸ë¨¼íŠ¸ ì‹¤í–‰ |
| `AggregateParallelResults` | SegmentRunnerFunction | ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼ ì§‘ê³„ (aggregator type) |
| `UpdateStateData` | StateDataManagerFunction | ìƒíƒœ ì••ì¶• ë° S3 ì˜¤í”„ë¡œë”© |
| `WaitForCallback` | StoreTaskTokenFunction | HITP Task Token ì €ì¥ |
| `PrepareStateAfterPause` | MergeCallbackFunction | HITP ì¬ê°œ í›„ ìƒíƒœ ë³‘í•© |
| `HandleAsyncLLM` | AsyncLLMHandlerFunction | ë¹„ë™ê¸° LLM ì²˜ë¦¬ |
| `AggregateMapReduceResults` | AggregateResultsArn | Map-Reduce ê²°ê³¼ ìµœì¢… ì§‘ê³„ |
| `AggregateBatchedResults` | AggregateResultsArn | Batched ê²°ê³¼ ìµœì¢… ì§‘ê³„ |

##### **EventBridge ë°œí–‰ (9ê°œ)**
| ìƒíƒœëª… | ì´ë²¤íŠ¸ íƒ€ì… | ìš©ë„ |
|--------|------------|------|
| `HandleInitFailure` | WorkflowLifecycleEvent (FAILED) | ì´ˆê¸°í™” ì‹¤íŒ¨ ì•Œë¦¼ |
| `NotifyLargeWorkflowWarning` | WorkflowLifecycleEvent (LARGE_WORKFLOW_WARNING) | ëŒ€í˜• ì›Œí¬í”Œë¡œìš° ê²½ê³  |
| `NotifyWorkflowStarted` | WorkflowLifecycleEvent (RUNNING) | ì›Œí¬í”Œë¡œìš° ì‹œì‘ ì•Œë¦¼ |
| `NotifyAsyncLLMProcessing` | WorkflowLifecycleEvent (ASYNC_LLM_PROCESSING) | ë¹„ë™ê¸° LLM ì²˜ë¦¬ ì¤‘ ì•Œë¦¼ |
| `PublishSucceededEvent` | WorkflowLifecycleEvent (COMPLETED) | ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì•Œë¦¼ |
| `NotifyExecutionSuccess` | WorkflowExecutionSucceeded | ìµœì¢… ì„±ê³µ ì•Œë¦¼ |
| `NotifyWorkflowCompleted` | WorkflowLifecycleEvent (COMPLETED) | Hybrid ëª¨ë“œ ì™„ë£Œ ì•Œë¦¼ |
| `NotifyExecutionFailure` | WorkflowLifecycleEvent (FAILED) | ì‹¤í–‰ ì‹¤íŒ¨ ì•Œë¦¼ |

##### **DynamoDB ì§ì ‘ í†µí•© (1ê°œ)**
| ìƒíƒœëª… | ì‘ì—… | ìš©ë„ |
|--------|------|------|
| `CheckForExistingExecution` | dynamodb:getItem | ë©±ë“±ì„± í‚¤ë¡œ ê¸°ì¡´ ì‹¤í–‰ ì¡°íšŒ (Cold Start ìµœì í™”) |

#### **Map ìƒíƒœ (3ê°œ)**
| ìƒíƒœëª… | ë™ì‹œì„± | Iterator í”Œë¡œìš° |
|--------|---------|-----------------|
| `ExecuteMapReduceMode` | ë™ì  (max_concurrency) | MapReduceSegmentRunner â†’ End |
| `ExecuteBatchedMode` | ê³ ì • (10) | BatchedSegmentRunner â†’ End |
| `ProcessParallelSegments` | ë™ì  (max_concurrency) | InitializeBranch â†’ ExecuteBranchSegment â†’ (ë£¨í”„) â†’ BranchComplete |

#### **Pass ìƒíƒœ (11ê°œ)**
| ìƒíƒœëª… | ìš©ë„ |
|--------|------|
| `PrepareSequentialBranch` | inner_partition_mapì„ partition_mapìœ¼ë¡œ êµì²´ |
| `HandleBranchError` | Lambda ì˜ˆì™¸ë¥¼ PARTIAL_FAILUREë¡œ ë³€í™˜ |
| `HandleBranchFailedStatus` | FAILED ìƒíƒœë¥¼ PARTIAL_FAILUREë¡œ ë³€í™˜ |
| `UpdateBranchSegment` | ë¸Œëœì¹˜ ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ì¤€ë¹„ |
| `UpdateBranchToSequential` | ë¸Œëœì¹˜ ë‚´ SEQUENTIAL_BRANCH ì²˜ë¦¬ |
| `BranchComplete` | ë¸Œëœì¹˜ ê²°ê³¼ ì¤€ë¹„ |
| `HandleMapError` | Map ì—ëŸ¬ ì‹œ ë¹ˆ ê²°ê³¼ ì¤€ë¹„ |
| `EnsureExecutionResult` | execution_result ê¸°ë³¸ê°’ ë³´ì¥ |
| `MergeExecutionResult` | ê¸°ë³¸ê°’ê³¼ ì‹¤ì œê°’ ë³‘í•© |
| `CleanupMergedState` | í˜ì´ë¡œë“œ ì •ë¦¬ (256KB ì œí•œ íšŒí”¼) |
| `UpdateStateDataFallback` | ì••ì¶• ì‹¤íŒ¨ ì‹œ í´ë°± |
| `ApplyMergedState` | HITP ì¬ê°œ í›„ ìƒíƒœ ì ìš© |
| `ProcessAsyncResult` | ë¹„ë™ê¸° LLM ê²°ê³¼ ì²˜ë¦¬ |
| `UpdateSegmentToRun` | ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ |
| `PrepareSuccessOutput` | ìµœì¢… ì„±ê³µ ì¶œë ¥ ì¤€ë¹„ |
| `PrepareHybridModeOutput` | Hybrid ëª¨ë“œ ì¶œë ¥ ì¤€ë¹„ |

---

## 3. Lambda í•¨ìˆ˜ ìŠ¤í‚¤ë§ˆ ë§¤í•‘

### 3.1 InitializeStateDataFunction

**ì…ë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "input": {
    "ownerId": "string",
    "workflowId": "string",
    "workflow_config": "object (optional)",
    "workflow_config_s3_path": "string (optional)",
    "initial_state": "object (optional)",
    "idempotency_key": "string",
    "MOCK_MODE": "boolean (optional)",
    "test_workflow_config": "object (optional)",
    "quota_reservation_id": "string (optional)"
  }
}
```

**ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "workflow_config_s3_path": "string",
  "state_s3_path": "string",
  "light_config": "object (minimal metadata)",
  "input": "object (preserved)",
  "state_history": "array",
  "ownerId": "string",
  "workflowId": "string",
  "segment_to_run": 0,
  "idempotency_key": "string",
  "quota_reservation_id": "string",
  "total_segments": "number",
  "partition_map": "array",
  "partition_map_s3_path": "string",
  "segment_manifest": "array",
  "segment_manifest_s3_path": "string",
  "max_loop_iterations": "number",
  "max_branch_iterations": "number",
  "loop_counter": 0,
  "max_concurrency": "number",
  "distributed_mode": "boolean",
  "distributed_strategy": "string",
  "llm_segments": "number",
  "hitp_segments": "number"
}
```

**SFN ì‚¬ìš© ìœ„ì¹˜:**
- `InitializeStateData` ìƒíƒœ (L135-182)

**ì£¼ìš” ë¡œì§:**
1. workflow_configë¥¼ S3ì— ì €ì¥í•˜ê±°ë‚˜ S3ì—ì„œ ë¡œë“œ
2. partition_workflow_advanced() í˜¸ì¶œí•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• 
3. ì´ˆê¸° ìƒíƒœ ìƒì„± ë° S3 ì €ì¥
4. max_loop_iterations ë™ì  ê³„ì‚° (ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ ê¸°ë°˜)
5. distributed_strategy ê²°ì • (MAP_REDUCE / BATCHED / SEQUENTIAL)

---

### 3.2 SegmentRunnerFunction

**ì…ë ¥ ìŠ¤í‚¤ë§ˆ (ì¼ë°˜ ì‹¤í–‰):**
```json
{
  "workflow_config_s3_path": "string",
  "state_s3_path": "string",
  "state_history": "array (optional)",
  "ownerId": "string",
  "workflowId": "string",
  "segment_to_run": "number",
  "idempotency_key": "string",
  "quota_reservation_id": "string (optional)",
  "total_segments": "number",
  "partition_map": "array",
  "partition_map_s3_path": "string (optional)",
  "max_concurrency": "number (optional)",
  "branch_config": "object (optional, for parallel branches)",
  "test_workflow_config": "object (optional, for E2E tests)"
}
```

**ì…ë ¥ ìŠ¤í‚¤ë§ˆ (Aggregator ëª¨ë“œ):**
```json
{
  "segment_type": "aggregator",
  "parallel_results": "array[branch_result]",
  "map_error": "object (optional)",
  "workflow_config_s3_path": "string",
  "state_s3_path": "string",
  "ownerId": "string",
  "workflowId": "string",
  "segment_to_run": "number",
  "idempotency_key": "string"
}
```

**ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "status": "CONTINUE | COMPLETE | PARALLEL_GROUP | SEQUENTIAL_BRANCH | PAUSE | PAUSED_FOR_HITP | FAILED | HALTED | SIGKILL | SKIPPED",
  "final_state": "object",
  "final_state_s3_path": "string",
  "next_segment_to_run": "number | null",
  "new_history_logs": "array",
  "error_info": "object | null",
  "branches": "array (if status=PARALLEL_GROUP)",
  "segment_type": "string",
  "inner_partition_map": "array (if status=SEQUENTIAL_BRANCH)",
  "execution_time": "number",
  "kernel_actions": "array (optional)",
  "total_segments": "number"
}
```

**SFN ì‚¬ìš© ìœ„ì¹˜:**
- `ExecuteSegment` (L453-540) - SEQUENTIAL ëª¨ë“œ
- `MapReduceSegmentRunner` (L329-359) - Map Iterator ë‚´ë¶€
- `BatchedSegmentRunner` (L402-432) - Map Iterator ë‚´ë¶€
- `ExecuteBranchSegment` (L706-793) - ProcessParallelSegments Iterator ë‚´ë¶€
- `AggregateParallelResults` (L1034-1061) - Aggregator ëª¨ë“œ
- `AggregateParallelResultsFromError` (L967-994) - Aggregator ëª¨ë“œ (ì—ëŸ¬ ì²˜ë¦¬)

**ì£¼ìš” ë¡œì§:**
1. **ì¼ë°˜ ëª¨ë“œ**: segment_config í•´ì„ â†’ ì›Œí¬í”Œë¡œìš° ë¹Œë“œ â†’ ì‹¤í–‰ â†’ ìƒíƒœ ì €ì¥
2. **Aggregator ëª¨ë“œ**: ë³‘ë ¬ ë¸Œëœì¹˜ ê²°ê³¼ ë³‘í•© â†’ ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ê²°ì •
3. **HITP ê°ì§€**: workflow_config.edgesì—ì„œ inter-segment HITP ì—£ì§€ ì²´í¬
4. **ìƒíƒœ ê´€ë¦¬**: 
   - S3 offload (>250KB)
   - Distributed Map ê°•ì œ offload (threshold=0)
   - Map branch pruning (ëŒ€ìš©ëŸ‰ í•„ë“œ ì œê±°)

---

### 3.3 StateDataManagerFunction

**ì…ë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "action": "update_and_compress",
  "state_data": "object (current state_data)",
  "execution_result": "object (from SegmentRunner)",
  "max_payload_size_kb": 200
}
```

**ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "light_config": "object",
  "workflow_config_s3_path": "string",
  "state_s3_path": "string",
  "state_history": "array",
  "ownerId": "string",
  "workflowId": "string",
  "segment_to_run": "number",
  "idempotency_key": "string",
  "quota_reservation_id": "string",
  "total_segments": "number",
  "partition_map": "array | null (if offloaded)",
  "partition_map_s3_path": "string",
  "segment_manifest": "array | null (if offloaded)",
  "segment_manifest_s3_path": "string",
  "max_concurrency": "number",
  "distributed_mode": "boolean",
  "distributed_strategy": "string",
  "loop_counter": "number",
  "max_loop_iterations": "number",
  "max_branch_iterations": "number",
  "llm_segments": "number",
  "hitp_segments": "number",
  "payload_size_kb": "number",
  "compression_applied": "boolean"
}
```

**SFN ì‚¬ìš© ìœ„ì¹˜:**
- `UpdateStateData` (L1062-1133) - ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ ì‹¤í–‰ í›„

**ì£¼ìš” ë¡œì§:**
1. execution_resultë¥¼ state_dataì— ë³‘í•©
2. í˜ì´ë¡œë“œ í¬ê¸° ê³„ì‚°
3. 200KB ì´ˆê³¼ ì‹œ partition_map, segment_manifest S3 ì˜¤í”„ë¡œë”©
4. state_history ì—…ë°ì´íŠ¸
5. segment_to_runì„ execution_result.next_segment_to_runìœ¼ë¡œ ì—…ë°ì´íŠ¸

---

### 3.4 StoreTaskTokenFunction

**ì…ë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "TaskToken": "string (Step Functions Task Token)",
  "conversation_id": "string (execution ID)",
  "execution_id": "string",
  "execution_name": "string",
  "idempotency_key": "string",
  "workflow_config_s3_path": "string",
  "state_s3_path": "string",
  "segment_to_run": "number",
  "partition_map": "array",
  "total_segments": "number",
  "ownerId": "string",
  "workflowId": "string",
  "state_data": "object",
  "MOCK_MODE": "boolean (optional)"
}
```

**ì¶œë ¥:**
- LambdaëŠ” ì¦‰ì‹œ ë°˜í™˜í•˜ê³  ë‚´ë¶€ì ìœ¼ë¡œ:
  1. TaskTokenì„ DynamoDBì— ì €ì¥ (Executions-v3-dev table)
  2. EventBridgeì— PAUSED ì´ë²¤íŠ¸ ë°œí–‰ (í”„ë¡ íŠ¸ì—”ë“œ ì•Œë¦¼)

**SFN ì‚¬ìš© ìœ„ì¹˜:**
- `WaitForCallback` (L1234-1259) - `.waitForTaskToken` íŒ¨í„´

**ì¬ê°œ ë©”ì»¤ë‹ˆì¦˜:**
- ì™¸ë¶€ API (`/api/v2/executions/{executionArn}/resume`)ê°€ TaskTokenê³¼ í•¨ê»˜ SendTaskSuccess í˜¸ì¶œ
- Step Functionsê°€ WaitForCallback ìƒíƒœì—ì„œ ì¬ê°œ

---

### 3.5 MergeCallbackFunction

**ì…ë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "previous_final_state": "object",
  "previous_final_state_s3_path": "string",
  "callback_result": "object (from resume API)",
  "state_data": "object",
  "segment_to_run": "number",
  "ownerId": "string",
  "workflowId": "string"
}
```

**ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "new_current_state": "object (merged state)",
  "new_state_s3_path": "string",
  "new_state_history": "array",
  "segment_to_run": "number"
}
```

**SFN ì‚¬ìš© ìœ„ì¹˜:**
- `PrepareStateAfterPause` (L1260-1288) - WaitForCallback ì´í›„

**ì£¼ìš” ë¡œì§:**
1. previous_final_stateë¥¼ S3ì—ì„œ ë¡œë“œ (S3 pathì¸ ê²½ìš°)
2. callback_resultì™€ ë³‘í•©
3. ìƒˆ ìƒíƒœë¥¼ S3ì— ì €ì¥
4. state_history ì—…ë°ì´íŠ¸

---

### 3.6 AsyncLLMHandlerFunction

**ì…ë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "TaskToken": "string",
  "execution_id": "string",
  "idempotency_key": "string",
  "workflow_config_s3_path": "string",
  "state_s3_path": "string",
  "ownerId": "string",
  "segment_to_run": "number",
  "workflowId": "string"
}
```

**ì¶œë ¥:**
- ë¹„ë™ê¸°ë¡œ LLM ì²˜ë¦¬ í›„ SendTaskSuccess í˜¸ì¶œ

**SFN ì‚¬ìš© ìœ„ì¹˜:**
- `HandleAsyncLLM` (L1374-1392) - `.waitForTaskToken` íŒ¨í„´

---

### 3.7 AggregateResultsArn (Distributed Results)

**ì…ë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "map_results": "array (MAP_REDUCE ê²°ê³¼)",
  "batch_results": "array (BATCHED ê²°ê³¼)",
  "ownerId": "string",
  "workflowId": "string",
  "execution_mode": "MAP_REDUCE | BATCHED"
}
```

**ì¶œë ¥ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "final_state": "object (aggregated)",
  "status": "COMPLETE"
}
```

**SFN ì‚¬ìš© ìœ„ì¹˜:**
- `AggregateMapReduceResults` (L360-379)
- `AggregateBatchedResults` (L433-452)

---

## 4. ë°ì´í„° íë¦„ ë° ì˜ì¡´ì„±

### 4.1 í•µì‹¬ ë°ì´í„° êµ¬ì¡°

#### **state_data (Step Functions ì»¨í…ìŠ¤íŠ¸)**
```json
{
  "workflow_config_s3_path": "s3://bucket/workflows/{workflowId}/config.json",
  "state_s3_path": "s3://bucket/workflows/{workflowId}/executions/{executionId}/state_{segmentId}.json",
  "partition_map": [
    {
      "id": 0,
      "nodes": [...],
      "edges": [],
      "type": "normal | llm | hitp | parallel_group | aggregator",
      "node_ids": ["n1", "n2"],
      "next_mode": "default | conditional | end",
      "default_next": 1
    }
  ],
  "partition_map_s3_path": "s3://... (when offloaded)",
  "total_segments": 10,
  "segment_to_run": 3,
  "loop_counter": 5,
  "max_loop_iterations": 100,
  "max_concurrency": 50,
  "distributed_strategy": "SEQUENTIAL | MAP_REDUCE | BATCHED",
  "llm_segments": 3,
  "hitp_segments": 2
}
```

#### **execution_result (SegmentRunner ì¶œë ¥)**
```json
{
  "status": "CONTINUE",
  "final_state": {
    "step_history": [...],
    "messages": [...],
    "query_results": [...]
  },
  "final_state_s3_path": "s3://...",
  "next_segment_to_run": 4,
  "new_history_logs": ["Segment 3 completed"],
  "error_info": null,
  "branches": null,
  "segment_type": "llm",
  "execution_time": 2.5,
  "total_segments": 10
}
```

#### **partition_map êµ¬ì¡°**
```json
[
  {
    "id": 0,
    "type": "normal",
    "nodes": [{...}],
    "edges": [],  // âš ï¸ í•­ìƒ ë¹„ì–´ìˆìŒ - intra-segment edgesë§Œ ì €ì¥
    "node_ids": ["trigger_node"],
    "next_mode": "default",
    "default_next": 1
  },
  {
    "id": 1,
    "type": "llm",
    "nodes": [{...}],
    "edges": [],
    "node_ids": ["llm_node_1"],
    "next_mode": "default",
    "default_next": 2
  },
  {
    "id": 2,
    "type": "parallel_group",
    "branches": [
      {
        "branch_id": "B0",
        "partition_map": [...],  // ë¸Œëœì¹˜ ë‚´ë¶€ ì„¸ê·¸ë¨¼íŠ¸
        "has_end": false,
        "target_node": "branch_start_node"
      }
    ],
    "node_ids": [],
    "branch_count": 3,
    "next_mode": "default",
    "default_next": 3  // aggregator segment
  },
  {
    "id": 3,
    "type": "aggregator",
    "nodes": [],
    "edges": [],
    "node_ids": [],
    "source_parallel_group": 2,
    "convergence_node": "merge_node",
    "next_mode": "default",
    "default_next": 4
  }
]
```

### 4.2 S3 ê²½ë¡œ êµ¬ì¡°

```
s3://{ExecutionBucket}/
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ {workflowId}/
â”‚       â”œâ”€â”€ config.json                    # workflow_config
â”‚       â”œâ”€â”€ partition_map.json             # partition_map (large workflows)
â”‚       â””â”€â”€ executions/
â”‚           â””â”€â”€ {executionId}/
â”‚               â”œâ”€â”€ state_0.json           # ì´ˆê¸° ìƒíƒœ
â”‚               â”œâ”€â”€ state_1.json           # segment 1 ì‹¤í–‰ í›„
â”‚               â”œâ”€â”€ state_2.json           # segment 2 ì‹¤í–‰ í›„
â”‚               â”œâ”€â”€ state_3.json           # ...
â”‚               â”œâ”€â”€ segment_manifest.json  # ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡ (distributed mode)
â”‚               â””â”€â”€ final_state.json       # ìµœì¢… ê²°ê³¼
```

### 4.3 ë°ì´í„° íë¦„ ë‹¤ì´ì–´ê·¸ë¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    InitializeStateDataFunction                   â”‚
â”‚  Input: workflow_config                                          â”‚
â”‚  Output: partition_map, total_segments, state_s3_path           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“ partition_map, segment_to_run=0
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ExecuteSegment (Loop)                         â”‚
â”‚  Input: segment_to_run, partition_map, state_s3_path           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                       â”‚
      â†“ CONTINUE              â†“ PARALLEL_GROUP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PrepareNext     â”‚    â”‚ ProcessParallelSegmentsâ”‚
â”‚ Segment         â”‚    â”‚ (Map State)            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚
       â”‚                      â†“ parallel_results[]
       â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚ AggregateParallelResults â”‚
       â”‚               â”‚ (SegmentRunner)          â”‚
       â”‚               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â†’
                  â”‚
                  â†“ execution_result
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UpdateStateData                               â”‚
â”‚  Input: state_data, execution_result                            â”‚
â”‚  Output: updated state_data (with S3 offload if >200KB)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“ state_data (segment_to_run++, loop_counter++)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CheckLoopLimit                                â”‚
â”‚  If loop_counter > max_loop_iterations: FAIL                    â”‚
â”‚  Else: â†’ ExecuteSegment                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. ì„¸ê·¸ë¨¼íŠ¸í™” ë¡œì§ ë¶„ì„

### 5.1 íŒŒí‹°ì…”ë‹ í”„ë¡œì„¸ìŠ¤

```python
# partition_service.pyì˜ partition_workflow_advanced()

1. DAG ê²€ì¦ (ì‚¬ì´í´ ê°ì§€)
   â†“
2. Forced segment starts ìˆ˜ì§‘ (í•©ë¥˜ì  ê°ì§€)
   â†“
3. run_partitioning() ì¬ê·€ í˜¸ì¶œ
   â”œâ”€ ì‹œì‘ ë…¸ë“œë¶€í„° BFS ìˆœíšŒ
   â”œâ”€ ë¶„í•  íŠ¸ë¦¬ê±°:
   â”‚  â€¢ HITP ì—£ì§€ ì§„ì… (is_hitp_start)
   â”‚  â€¢ LLM ë…¸ë“œ (is_llm)
   â”‚  â€¢ Merge point (in-degree > 1)
   â”‚  â€¢ Branch point (out-degree > 1)
   â”‚  â€¢ Forced start (í•©ë¥˜ì )
   â”‚  â€¢ Inline parallel_group ë…¸ë“œ
   â”œâ”€ ë¸Œëœì¹˜ ì²˜ë¦¬:
   â”‚  â€¢ ê° ë¸Œëœì¹˜ ì¬ê·€ íŒŒí‹°ì…”ë‹
   â”‚  â€¢ Parallel group + Aggregator ìƒì„±
   â””â”€ flush_local(): ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
   â†“
4. process_links_recursive()
   â”œâ”€ next_mode ì„¤ì • (default/conditional/end)
   â”œâ”€ Aggregator â†’ Convergence node ì—°ê²°
   â””â”€ ë¸Œëœì¹˜ ì¢…ë£Œ ê²€ì¦
   â†“
5. ë°˜í™˜: {partition_map, total_segments, metadata}
```

### 5.2 create_segment() ë¡œì§

```python
def create_segment(nodes_map, edges_list, s_type, override_id, config):
    # 1. ë…¸ë“œ íƒ€ì… ì •ì • (code â†’ operator)
    for node in nodes_map.values():
        if node.get("type") == "code":
            node["type"] = "operator"
    
    # 2. âš ï¸ PROBLEM: ì„¸ê·¸ë¨¼íŠ¸ ë‚´ë¶€ ì—£ì§€ë§Œ ì¶”ê°€
    if config:
        all_edges = config.get("edges", [])
        for edge in all_edges:
            source, target = edge.get("source"), edge.get("target")
            if source in nodes_map and target in nodes_map:  # â† ì–‘ìª½ ë‹¤ ê°™ì€ segmentì— ìˆì–´ì•¼!
                edges_list.append(edge)
    
    # 3. ìœ„ìƒ ì •ë ¬ (DynamicWorkflowBuilderëŠ” nodes[0]ì„ entry pointë¡œ ì‚¬ìš©)
    sorted_nodes = _topological_sort_nodes(nodes_map, edges_list)
    
    # 4. ì„¸ê·¸ë¨¼íŠ¸ ë°˜í™˜
    return {
        "id": seg_id,
        "nodes": sorted_nodes,
        "edges": edges_list,  # â† intra-segment edgesë§Œ í¬í•¨!
        "type": s_type,
        "node_ids": [n["id"] for n in sorted_nodes]
    }
```

### 5.3 ì„¸ê·¸ë¨¼íŠ¸ ê°„ ì—°ê²° (next_mode)

```python
# process_links_recursive()ì—ì„œ ì„¤ì •

for seg in segments:
    if seg["type"] == "aggregator":
        # AggregatorëŠ” convergence_nodeë¡œ ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ì°¾ê¸°
        convergence_node = seg.get("convergence_node")
        if convergence_node in node_to_seg_map:
            next_seg_id = node_to_seg_map[convergence_node]
            seg["next_mode"] = "default"
            seg["default_next"] = next_seg_id
    else:
        # ì¼ë°˜ ì„¸ê·¸ë¨¼íŠ¸: node_idsì˜ outgoing edges í™•ì¸
        exit_edges = []
        for node_id in seg["node_ids"]:
            for edge in outgoing_edges.get(node_id, []):
                target = edge.get("target")
                if target in node_to_seg_map:
                    target_seg = node_to_seg_map[target]
                    if target_seg != seg["id"]:  # ë‹¤ë¥¸ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ê°€ëŠ” ì—£ì§€
                        exit_edges.append({"edge": edge, "target_segment": target_seg})
        
        if len(exit_edges) == 0:
            seg["next_mode"] = "end"
        elif len(exit_edges) == 1:
            seg["next_mode"] = "default"
            seg["default_next"] = exit_edges[0]["target_segment"]
        else:
            seg["next_mode"] = "conditional"
            seg["branches"] = [...]
```

**âš ï¸ ë¬¸ì œì :**
- `exit_edges`ë¥¼ ìˆ˜ì§‘í•˜ì§€ë§Œ ì—£ì§€ì˜ **íƒ€ì… ì •ë³´**ëŠ” ë¬´ì‹œë¨
- HITP, loop_exit, conditional ê°™ì€ ë©”íƒ€ë°ì´í„° ì†ì‹¤
- `next_mode`ëŠ” ë‹¨ìˆœíˆ ê°œìˆ˜ë§Œ ê¸°ë°˜ìœ¼ë¡œ ê²°ì • (1ê°œ=default, ì—¬ëŸ¬ê°œ=conditional)

---

## 6. ë¬¸ì œì  ë° ë¦¬íŒ©í† ë§ ê¶Œì¥ì‚¬í•­

### 6.1 ğŸ”´ Critical Issues

#### **Issue 1: Inter-Segment ì—£ì§€ ì •ë³´ ì™„ì „ ì†ì‹¤**

**í˜„ì¬ ìƒí™©:**
- `partition_map[i].edges`ëŠ” í•­ìƒ ë¹„ì–´ìˆìŒ (intra-segment edgesë§Œ ì €ì¥)
- segment ê°„ ì—°ê²°ì€ `next_mode`/`default_next`ë¡œë§Œ í‘œí˜„
- HITP, loop_exit, conditional routing ì •ë³´ ëª¨ë‘ ì†ì‹¤

**ì˜í–¥:**
```python
# partition_service.py L330-340
if source in nodes_map and target in nodes_map:  # â† ë¬¸ì œ!
    edges_list.append(edge)

# ê²°ê³¼:
# Segment 0 (node A) â†’ HITP edge â†’ Segment 1 (node B)
# â†’ HITP ì—£ì§€ ì •ë³´ê°€ partition_mapì— ì €ì¥ ì•ˆë¨!
```

**í˜„ì¬ ìš°íšŒ ì†”ë£¨ì…˜:**
```python
# segment_runner_service.py (4ê°œ ì§€ì ì— ì¤‘ë³µ ì½”ë“œ)
workflow_config = event.get('workflow_config')
edges = workflow_config.get('edges', [])
for edge in edges:
    if (edge.get('source') in current_node_ids and 
        edge.get('target') in next_node_ids and
        edge.get('type') in {'hitp', 'human_in_the_loop', 'pause'}):
        hitp_detected = True
        break
```

**ë¬¸ì œì :**
- âœ… HITPëŠ” ê°ì§€ë¨
- âŒ loop_exitëŠ” ì²´í¬ ì•ˆí•¨
- âŒ conditional routing ì •ë³´ ì—†ìŒ
- âŒ ë§¤ë²ˆ ì „ì²´ workflow_config ìŠ¤ìº” (O(E) ì„±ëŠ¥ ì €í•˜)
- âŒ 4ê°œ ì§€ì ì— ì¤‘ë³µ ì½”ë“œ (ìœ ì§€ë³´ìˆ˜ ë¹„ìš©)

---

#### **Issue 2: partition_map ìŠ¤í‚¤ë§ˆì˜ ë¶ˆì™„ì „ì„±**

**í˜„ì¬ partition_map êµ¬ì¡°:**
```json
{
  "id": 1,
  "nodes": [...],
  "edges": [],  // â† í•­ìƒ ë¹„ì–´ìˆìŒ
  "type": "normal",
  "node_ids": ["n1", "n2"],
  "next_mode": "default",
  "default_next": 2  // â† ì—£ì§€ ë©”íƒ€ë°ì´í„° ì—†ìŒ!
}
```

**ë¬¸ì œ:**
1. `default_next`ëŠ” ì •ìˆ˜ IDë§Œ ì €ì¥ â†’ ì—£ì§€ íƒ€ì…/ì¡°ê±´ ì •ë³´ ì—†ìŒ
2. `next_mode: "conditional"`ì¼ ë•Œë„ ì¡°ê±´ í‘œí˜„ì‹ ì €ì¥ ì•ˆë¨
3. Loop exit ì—£ì§€ì™€ ì¼ë°˜ ì—£ì§€ êµ¬ë¶„ ë¶ˆê°€

---

#### **Issue 3: ìƒíƒœ ë¨¸ì‹ ì˜ ë³µì¡ë„**

**í†µê³„:**
- ì´ ìƒíƒœ: 55ê°œ
- Choice ìƒíƒœ: 16ê°œ (ë³µì¡í•œ ë¶„ê¸° ë¡œì§)
- Lambda í˜¸ì¶œ: 11ê°œ (ë‹¤ì–‘í•œ í•¨ìˆ˜)
- EventBridge ë°œí–‰: 9ê°œ (ì•Œë¦¼ ê³¼ë¶€í•˜)
- Map ìƒíƒœ: 3ê°œ (ì¤‘ì²©ëœ ë³‘ë ¬ ì²˜ë¦¬)

**ë¬¸ì œ:**
1. **ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€**: 55ê°œ ìƒíƒœì˜ íë¦„ ì¶”ì  ì–´ë ¤ì›€
2. **ë””ë²„ê¹… ë³µì¡ì„±**: ì–´ëŠ ìƒíƒœì—ì„œ ì—ëŸ¬ë‚¬ëŠ”ì§€ íŒŒì•…í•˜ê¸° ì–´ë ¤ì›€
3. **ì„±ëŠ¥ ì˜¤ë²„í—¤ë“œ**: EventBridge 9ë²ˆ í˜¸ì¶œ (ì•Œë¦¼ë§ˆë‹¤ Lambda trigger)
4. **ìƒíƒœ ì´ë¦„ ì¤‘ë³µ**: `NotifyWorkflowStarted`, `NotifyWorkflowCompleted`, `NotifyExecutionSuccess` ë“± ìœ ì‚¬ ê¸°ëŠ¥

---

#### **Issue 4: ë°ì´í„° ì „ë‹¬ íŒ¨í„´ì˜ ì¼ê´€ì„± ë¶€ì¡±**

**Case 1: ExecuteSegment â†’ CheckSegmentStatus**
```json
// ResultPath: "$.execution_result"
{
  "state_data": {...},
  "execution_result": {
    "status": "CONTINUE",
    "final_state": {...},
    "next_segment_to_run": 2
  }
}
```

**Case 2: ProcessParallelSegments â†’ AggregateParallelResults**
```json
// ResultPath: "$.parallel_results"
{
  "state_data": {...},
  "parallel_results": [...]  // â† ë‹¤ë¥¸ ì´ë¦„!
}
```

**Case 3: WaitForCallback â†’ PrepareStateAfterPause**
```json
// ResultPath: "$.callback_result"
{
  "state_data": {...},
  "execution_result": {...},
  "callback_result": {...}  // â† ë˜ ë‹¤ë¥¸ ì´ë¦„!
}
```

**ë¬¸ì œ:**
- ì¼ê´€ë˜ì§€ ì•Šì€ í•„ë“œëª… (`execution_result`, `parallel_results`, `callback_result`)
- Choice ìƒíƒœì—ì„œ ê²½ë¡œê°€ ë‹¬ë¼ì ¸ JSON Path ë³µì¡í•´ì§
- ì—ëŸ¬ ì²˜ë¦¬ ì‹œ ì–´ë–¤ í•„ë“œë¥¼ ì°¸ì¡°í•´ì•¼ í• ì§€ í˜¼ë€

---

#### **Issue 5: S3 Offload ë¡œì§ ì¤‘ë³µ**

**4ê³³ì—ì„œ ë™ì¼ ë¡œì§ ë°˜ë³µ:**
1. `segment_runner_service.py` L3139-3147 (Partial Failure)
2. `segment_runner_service.py` L3353-3361 (E2E Test)
3. `segment_runner_service.py` L3377-3385 (Final Segment)
4. `segment_runner_service.py` L3405-3413 (Continue)

```python
# ì¤‘ë³µ ì½”ë“œ (4ë²ˆ ë°˜ë³µ)
response_final_state = final_state
if output_s3_path:
    response_final_state = {
        "__s3_offloaded": True,
        "__s3_path": output_s3_path,
        "__original_size_kb": len(json.dumps(final_state, ...)) / 1024
    }
    logger.info(f"[S3 Offload] Replaced final_state...")
```

---

### 6.2 ğŸŸ¡ Medium Priority Issues

#### **Issue 6: Loop Counterì˜ ì´ì¤‘ ê´€ë¦¬**

**Step Functions ë ˆë²¨:**
```json
{
  "state_data": {
    "loop_counter": 5,
    "max_loop_iterations": 100
  }
}
```

**Lambda ë ˆë²¨ (segment_runner):**
```python
# Parallel branch iteratorì—ì„œ ë³„ë„ loop_counter
loop_counter = event.get('loop_counter', 0)
# Loop exit ì¡°ê±´ë„ ë³„ë„ ê´€ë¦¬
```

**ë¬¸ì œ:**
- SFNê³¼ Lambdaì—ì„œ ê°ê° ë£¨í”„ ì¹´ìš´íŒ…
- max_branch_iterations vs max_loop_iterations í˜¼ë€
- ë¸Œëœì¹˜ ë‚´ë¶€ ë£¨í”„ëŠ” SFN ë£¨í”„ ì¹´ìš´íŠ¸ì— í¬í•¨ ì•ˆë¨

---

#### **Issue 7: ì—ëŸ¬ í•¸ë“¤ë§ì˜ ë¶ˆì¼ì¹˜**

**Case 1: ExecuteSegment Catch**
```json
{
  "ErrorEquals": ["States.ALL"],
  "ResultPath": "$.execution_result.error_info",
  "Next": "NotifyExecutionFailure"
}
```

**Case 2: ExecuteBranchSegment Catch**
```json
{
  "ErrorEquals": ["States.ALL"],
  "ResultPath": "$.branch_error",
  "Next": "HandleBranchError"
}
```

**Case 3: UpdateStateData Catch**
```json
{
  "ErrorEquals": ["States.ALL"],
  "ResultPath": "$.compression_error",
  "Next": "UpdateStateDataFallback"
}
```

**ë¬¸ì œ:**
- ì—ëŸ¬ ì €ì¥ ê²½ë¡œ ë¶ˆì¼ì¹˜ (`.execution_result.error_info`, `.branch_error`, `.compression_error`)
- ì¼ë¶€ëŠ” ì¦‰ì‹œ ì‹¤íŒ¨, ì¼ë¶€ëŠ” í´ë°± ì²˜ë¦¬
- ì—ëŸ¬ ë³µêµ¬ ì „ëµ ë¶ˆëª…í™•

---

#### **Issue 8: Distributed Mode ì„ íƒ ë¡œì§ ë¶ˆíˆ¬ëª…**

```python
# InitializeStateDataFunctionì—ì„œ ê²°ì •
if total_segments > 200:
    distributed_strategy = "MAP_REDUCE"
elif total_segments > 50:
    distributed_strategy = "BATCHED"
else:
    distributed_strategy = "SEQUENTIAL"
```

**ë¬¸ì œ:**
1. í•˜ë“œì½”ë”©ëœ ì„ê³„ê°’ (50, 200)
2. ì›Œí¬í”Œë¡œìš° íŠ¹ì„± ë¬´ì‹œ (LLM ë¹„ì¤‘, HITP ì—¬ë¶€, ê·¸ë˜í”„ ë³µì¡ë„)
3. ì‚¬ìš©ì override ë¶ˆê°€

---

### 6.3 ğŸŸ¢ Low Priority Issues

#### **Issue 9: EventBridge ë°œí–‰ ë‚¨ë°œ**

**9ê°œ ìƒíƒœì—ì„œ ë°œí–‰:**
- HandleInitFailure
- NotifyLargeWorkflowWarning
- NotifyWorkflowStarted
- NotifyAsyncLLMProcessing
- PublishSucceededEvent
- NotifyExecutionSuccess
- NotifyWorkflowCompleted
- NotifyExecutionFailure

**ë¬¸ì œ:**
- ëŒ€ë¶€ë¶„ ì•Œë¦¼ ëª©ì 
- ì¼ë¶€ëŠ” ì¤‘ë³µ (PublishSucceededEvent + NotifyExecutionSuccess)
- EventBridge â†’ Lambda â†’ WebSocket ê²½ë¡œë¡œ ì˜¤ë²„í—¤ë“œ

---

#### **Issue 10: Pass ìƒíƒœ ê³¼ë‹¤ ì‚¬ìš©**

**11ê°œ Pass ìƒíƒœ:**
- ëŒ€ë¶€ë¶„ Parameters ë³€í™˜ ìš©ë„
- Lambdaì—ì„œ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë¡œì§ë„ í¬í•¨

**ì˜ˆì‹œ:**
```json
// UpdateSegmentToRun (L1490-1527)
{
  "Type": "Pass",
  "Parameters": {
    "segment_to_run.$": "$.execution_result.next_segment_to_run",
    "loop_counter.$": "States.MathAdd($.state_data.loop_counter, 1)",
    ...
  }
}
```

â†’ Lambdaì—ì„œ ì²˜ë¦¬í•˜ë©´ SFN ìƒíƒœ 1ê°œ ì¤„ì¼ ìˆ˜ ìˆìŒ

---

## 7. ë¦¬íŒ©í† ë§ ê¶Œì¥ì‚¬í•­

### 7.1 ğŸ¯ Phase 1: Critical Fixes (P0)

#### **1.1 Partition Map ìŠ¤í‚¤ë§ˆ í™•ì¥**

**ìƒˆ ìŠ¤í‚¤ë§ˆ:**
```json
{
  "id": 1,
  "nodes": [...],
  "edges": [],  // intra-segment edges
  "outgoing_edges": [  // â† NEW: inter-segment edges
    {
      "source_node": "node_in_this_segment",
      "target_node": "node_in_next_segment",
      "target_segment": 2,
      "edge_type": "hitp",
      "condition": null,
      "is_loop_exit": false,
      "metadata": {
        "label": "Human Review",
        "style": "dashed"
      }
    }
  ],
  "type": "llm",
  "node_ids": ["llm_node"],
  "next_mode": "default",
  "default_next": 2
}
```

**êµ¬í˜„:**
```python
# partition_service.py - create_segment() ìˆ˜ì •

def create_segment(nodes_map, edges_list, s_type, override_id, config):
    # ... ê¸°ì¡´ ì½”ë“œ ...
    
    # [NEW] Inter-segment edges ìˆ˜ì§‘
    outgoing_edges = []
    if config:
        all_edges = config.get("edges", [])
        for edge in all_edges:
            source = edge.get("source")
            target = edge.get("target")
            
            # Intra-segment edge
            if source in nodes_map and target in nodes_map:
                edges_list.append(edge)
            
            # Inter-segment edge
            elif source in nodes_map and target not in nodes_map:
                outgoing_edges.append({
                    "source_node": source,
                    "target_node": target,
                    "edge_type": edge.get("type", "normal"),
                    "condition": edge.get("condition"),
                    "is_loop_exit": edge.get("data", {}).get("isLoopExit", False),
                    "metadata": {
                        "label": edge.get("label"),
                        "style": edge.get("style"),
                        "animated": edge.get("animated")
                    }
                })
    
    return {
        "id": seg_id,
        "nodes": sorted_nodes,
        "edges": edges_list,
        "outgoing_edges": outgoing_edges,  # â† NEW
        "type": s_type,
        "node_ids": [...]
    }
```

**segment_runner_service.py ìˆ˜ì •:**
```python
# HITP ê°ì§€ ë¡œì§ ê°„ì†Œí™”

def check_inter_segment_edges(segment_config, next_segment_config):
    """
    í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ì˜ outgoing_edgesì—ì„œ ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ê°€ëŠ” ì—£ì§€ ì •ë³´ ì¶”ì¶œ
    """
    outgoing_edges = segment_config.get("outgoing_edges", [])
    next_node_ids = set(next_segment_config.get("node_ids", []))
    
    for edge in outgoing_edges:
        if edge["target_node"] in next_node_ids:
            return {
                "edge_type": edge["edge_type"],
                "is_loop_exit": edge["is_loop_exit"],
                "condition": edge["condition"],
                "metadata": edge["metadata"]
            }
    
    return None

# ì‚¬ìš©:
edge_info = check_inter_segment_edges(current_seg, next_seg)
if edge_info and edge_info["edge_type"] in {"hitp", "human_in_the_loop", "pause"}:
    return {"status": "PAUSED_FOR_HITP", ...}
```

**ì¥ì :**
- âœ… workflow_config ìŠ¤ìº” ë¶ˆí•„ìš” (O(E) â†’ O(1))
- âœ… 4ê³³ ì¤‘ë³µ ì½”ë“œ â†’ 1ê°œ í•¨ìˆ˜ë¡œ í†µí•©
- âœ… loop_exit, conditional ì§€ì›
- âœ… ì—£ì§€ ë©”íƒ€ë°ì´í„° ë³´ì¡´

---

#### **1.2 State Data Manager í†µí•©**

**í˜„ì¬ ë¬¸ì œ:**
- UpdateStateData Lambda (L1062-1133)
- UpdateStateDataFallback Pass (L1134-1173)
- ê±°ì˜ ë™ì¼í•œ Parameters ë¸”ë¡ (40ì¤„ ì¤‘ë³µ)

**ì œì•ˆ:**
```json
// StateDataManagerFunction ì‘ë‹µ í‘œì¤€í™”
{
  "state_data": {  // â† ì§ì ‘ state_data ë°˜í™˜
    "workflow_config_s3_path": "...",
    "state_s3_path": "...",
    "segment_to_run": "...",
    ...
  }
}

// SFNì—ì„œ ì‚¬ìš©
{
  "Type": "Task",
  "Resource": "StateDataManagerArn",
  "ResultPath": "$.state_data",  // â† ì§ì ‘ êµì²´
  "Next": "IsPauseNeeded"
}
```

**Fallback ì œê±°:**
- Lambda ë‚´ë¶€ì—ì„œ ì—ëŸ¬ ì²˜ë¦¬
- ì••ì¶• ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
- SFN í´ë°± ìƒíƒœ ë¶ˆí•„ìš”

---

#### **1.3 Execution Result êµ¬ì¡° í‘œì¤€í™”**

**í‘œì¤€ ì‘ë‹µ ì¸í„°í˜ì´ìŠ¤:**
```typescript
interface ExecutionResult {
  status: 'CONTINUE' | 'COMPLETE' | 'PARALLEL_GROUP' | 'PAUSE' | 'FAILED';
  final_state: object;
  final_state_s3_path: string;
  next_segment_to_run?: number;
  error_info?: object;
  // íƒ€ì…ë³„ optional í•„ë“œ
  branches?: Array<BranchConfig>;  // PARALLEL_GROUP
  inner_partition_map?: Array<Segment>;  // SEQUENTIAL_BRANCH
  routing_info?: {  // â† NEW
    inter_segment_edge?: InterSegmentEdge;
    requires_hitp: boolean;
    requires_loop_exit: boolean;
    conditional_routes?: Array<ConditionalRoute>;
  };
}
```

**ëª¨ë“  Lambdaê°€ ë™ì¼ êµ¬ì¡° ë°˜í™˜:**
- ExecuteSegment
- MapReduceSegmentRunner
- BatchedSegmentRunner
- ExecuteBranchSegment
- AggregateParallelResults

**SFN ResultPath í‘œì¤€í™”:**
```json
{
  "ResultPath": "$.execution_result"  // â† í•­ìƒ ë™ì¼
}
```

---

### 7.2 ğŸ”„ Phase 2: Refactoring (P1)

#### **2.1 ìƒíƒœ ë¨¸ì‹  ê°„ì†Œí™”**

**í˜„ì¬:** 55ê°œ ìƒíƒœ
**ëª©í‘œ:** 35ê°œ ì´í•˜

**í†µí•© ê°€ëŠ¥í•œ ìƒíƒœ:**

1. **ì•Œë¦¼ ìƒíƒœ í†µí•© (9â†’3ê°œ)**
```json
{
  "NotifyLifecycleEvent": {
    "Type": "Task",
    "Resource": "arn:aws:states:::events:putEvents",
    "Parameters": {
      "Entries": [{
        "Detail": {
          "status.$": "$.notification.status",
          "message.$": "$.notification.message",
          ...
        }
      }]
    }
  }
}
```

- NotifyWorkflowStarted â†’ NotifyLifecycleEvent (status=RUNNING)
- PublishSucceededEvent â†’ NotifyLifecycleEvent (status=COMPLETED)
- NotifyExecutionFailure â†’ NotifyLifecycleEvent (status=FAILED)

2. **ì—ëŸ¬ í•¸ë“¤ëŸ¬ í†µí•© (3â†’1ê°œ)**
```json
{
  "HandleExecutionError": {
    "Type": "Pass",
    "Parameters": {
      "status": "PARTIAL_FAILURE",
      "error_source.$": "$.error_source",
      "error_info.$": "States.JsonMerge($.default_error, $.actual_error, false)"
    }
  }
}
```

- HandleBranchError â†’ HandleExecutionError
- HandleBranchFailedStatus â†’ HandleExecutionError
- HandleMapError â†’ HandleExecutionError

3. **ìƒíƒœ ì—…ë°ì´íŠ¸ í†µí•© (3â†’1ê°œ)**
```json
{
  "PrepareNextIteration": {
    "Type": "Task",
    "Resource": "PrepareIterationArn",  // ìƒˆ Lambda
    "Parameters": {
      "iteration_type.$": "$.iteration_type",  // segment/branch/async
      "current_state.$": "$.state_data",
      "execution_result.$": "$.execution_result"
    }
  }
}
```

- UpdateSegmentToRun â†’ PrepareNextIteration (type=segment)
- UpdateBranchSegment â†’ PrepareNextIteration (type=branch)
- ProcessAsyncResult â†’ PrepareNextIteration (type=async)

---

#### **2.2 Loop Counter ë‹¨ì¼í™”**

**í˜„ì¬:**
```json
{
  "state_data": {
    "loop_counter": 5,
    "max_loop_iterations": 100,
    "max_branch_iterations": 50
  },
  "branch_state": {
    "loop_counter": 2  // â† ë³„ë„ ê´€ë¦¬!
  }
}
```

**ì œì•ˆ:**
```json
{
  "state_data": {
    "iteration_stack": [
      {"type": "main", "counter": 5, "max": 100},
      {"type": "branch", "counter": 2, "max": 50},
      {"type": "nested_loop", "counter": 0, "max": 10}
    ]
  }
}
```

**Lambda í•¨ìˆ˜:**
```python
def push_iteration_context(stack, type, max):
    stack.append({"type": type, "counter": 0, "max": max})

def pop_iteration_context(stack):
    return stack.pop()

def increment_iteration(stack):
    stack[-1]["counter"] += 1
    return stack[-1]["counter"] > stack[-1]["max"]  # exceeded?
```

---

#### **2.3 Distributed Strategy ì„ íƒ ê°œì„ **

**í˜„ì¬:** í•˜ë“œì½”ë”©ëœ ì„ê³„ê°’ (50, 200)

**ì œì•ˆ:**
```python
def calculate_complexity_score(partition_result):
    """
    ì›Œí¬í”Œë¡œìš° ë³µì¡ë„ ì ìˆ˜ ê³„ì‚° (0-100)
    """
    total_segments = partition_result["total_segments"]
    llm_segments = partition_result["llm_segments"]
    hitp_segments = partition_result["hitp_segments"]
    parallel_groups = partition_result["parallel_groups"]
    total_branches = partition_result["total_branches"]
    
    # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì ìˆ˜
    score = (
        total_segments * 1.0 +
        llm_segments * 2.0 +  # LLMì€ ëŠë¦¬ë¯€ë¡œ ê°€ì¤‘ì¹˜ ë†’ìŒ
        hitp_segments * 0.5 +  # HITPëŠ” ëŒ€ê¸° ì‹œê°„ì´ë¯€ë¡œ ê°€ì¤‘ì¹˜ ë‚®ìŒ
        parallel_groups * 3.0 +  # ë³‘ë ¬ ê·¸ë£¹ì€ ë³µì¡ë„ ë†’ìŒ
        total_branches * 1.5
    )
    
    return min(score, 100)

def select_strategy(complexity_score, user_preference=None):
    """
    ë³µì¡ë„ ì ìˆ˜ ê¸°ë°˜ ì „ëµ ì„ íƒ
    """
    if user_preference:
        return user_preference
    
    if complexity_score > 70:
        return "MAP_REDUCE"  # ê³ ë³µì¡ë„: ìµœëŒ€ ë™ì‹œì„±
    elif complexity_score > 30:
        return "BATCHED"  # ì¤‘ë³µì¡ë„: ì œì–´ëœ ë™ì‹œì„±
    else:
        return "SEQUENTIAL"  # ì €ë³µì¡ë„: ìˆœì°¨ ì‹¤í–‰
```

---

### 7.3 ğŸš€ Phase 3: ìµœì í™” (P2)

#### **3.1 S3 Offload í—¬í¼ í•¨ìˆ˜í™”**

**ê³µí†µ í•¨ìˆ˜:**
```python
# common/s3_offload_helper.py

def prepare_response_with_offload(final_state, output_s3_path, threshold_kb=250):
    """
    S3 offload ì‹œ ì‘ë‹µ í˜ì´ë¡œë“œ ìµœì†Œí™”
    """
    if not output_s3_path:
        return final_state
    
    state_size = len(json.dumps(final_state, ensure_ascii=False).encode('utf-8'))
    
    if state_size < threshold_kb * 1024:
        return final_state  # ì‘ìœ¼ë©´ ê·¸ëŒ€ë¡œ
    
    # í° ìƒíƒœëŠ” ë©”íƒ€ë°ì´í„°ë§Œ
    return {
        "__s3_offloaded": True,
        "__s3_path": output_s3_path,
        "__original_size_kb": state_size / 1024
    }
```

**ì‚¬ìš©:**
```python
# segment_runner_service.py

response_final_state = prepare_response_with_offload(
    final_state, 
    output_s3_path
)

return {
    "status": "COMPLETE",
    "final_state": response_final_state,
    ...
}
```

---

#### **3.2 Partition Map ìºì‹±**

**í˜„ì¬:** ë§¤ë²ˆ S3ì—ì„œ ë¡œë“œ

**ì œì•ˆ:**
```python
# Lambda Layerì— ìºì‹± ë¡œì§ ì¶”ê°€

import hashlib
from functools import lru_cache

@lru_cache(maxsize=100)
def get_partition_map_cached(partition_map_s3_path):
    """
    partition_mapì„ ë©”ëª¨ë¦¬ ìºì‹œ (Lambda ì¬ì‚¬ìš© ì‹œ)
    """
    key = hashlib.md5(partition_map_s3_path.encode()).hexdigest()
    return s3.get_object(Bucket=bucket, Key=key)

# ì‚¬ìš©
partition_map = get_partition_map_cached(partition_map_s3_path)
```

**íš¨ê³¼:**
- ë™ì¼ ì‹¤í–‰ ë‚´ ë°˜ë³µ í˜¸ì¶œ ì‹œ S3 GET 0íšŒ
- Lambda warm start ì‹œ ìºì‹œ ìœ ì§€

---

#### **3.3 EventBridge â†’ SQS ë¹„ë™ê¸° ì²˜ë¦¬**

**í˜„ì¬:** EventBridge â†’ Lambda â†’ WebSocket (ë™ê¸°)

**ì œì•ˆ:**
```
EventBridge â†’ SQS â†’ Lambda (Batch) â†’ WebSocket (ë¹„ë™ê¸°)
```

**ì¥ì :**
- ì•Œë¦¼ ì§€ì—° í—ˆìš© (0.5~1ì´ˆ)
- Lambda í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œ (ë°°ì¹­)
- ì‹¤íŒ¨ ì¬ì‹œë„ ìë™ ì²˜ë¦¬

---

## 8. ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

### 8.1 Phase 1 êµ¬í˜„ (Critical - 2ì£¼)

**Week 1: Partition Map ìŠ¤í‚¤ë§ˆ í™•ì¥**
- Day 1-2: `create_segment()` ìˆ˜ì • ë° í…ŒìŠ¤íŠ¸
- Day 3-4: `segment_runner_service.py` HITP ê°ì§€ ë¡œì§ êµì²´
- Day 5: í†µí•© í…ŒìŠ¤íŠ¸ (HITP, loop_exit, conditional)

**Week 2: State Data êµ¬ì¡° í‘œì¤€í™”**
- Day 1-2: ExecutionResult ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- Day 3-4: ëª¨ë“  Lambda í•¨ìˆ˜ ì‘ë‹µ ìˆ˜ì •
- Day 5: SFN ResultPath í‘œì¤€í™” ë° í…ŒìŠ¤íŠ¸

### 8.2 Phase 2 êµ¬í˜„ (Refactoring - 3ì£¼)

**Week 3-4: ìƒíƒœ ë¨¸ì‹  ê°„ì†Œí™”**
- ì•Œë¦¼ ìƒíƒœ í†µí•© (3ì¼)
- ì—ëŸ¬ í•¸ë“¤ëŸ¬ í†µí•© (3ì¼)
- ìƒíƒœ ì—…ë°ì´íŠ¸ í†µí•© (4ì¼)

**Week 5: Loop Counter ë° Strategy ê°œì„ **
- iteration_stack êµ¬í˜„ (2ì¼)
- complexity_score ê³„ì‚° (2ì¼)
- í†µí•© í…ŒìŠ¤íŠ¸ (1ì¼)

### 8.3 Phase 3 êµ¬í˜„ (ìµœì í™” - 1ì£¼)

**Week 6: ì„±ëŠ¥ ìµœì í™”**
- S3 Offload í—¬í¼ (1ì¼)
- Partition Map ìºì‹± (2ì¼)
- EventBridge â†’ SQS (2ì¼)

---

## 9. ê²°ë¡ 

### 9.1 í•µì‹¬ ë¬¸ì œ ìš”ì•½

1. **âš ï¸ CRITICAL**: Inter-segment ì—£ì§€ ì •ë³´ ì†ì‹¤
   - HITP, loop_exit, conditional routing ë¶ˆê°€
   - ë§¤ë²ˆ ì „ì²´ workflow_config ìŠ¤ìº” (ì„±ëŠ¥ ì €í•˜)

2. **âš ï¸ HIGH**: ìƒíƒœ ë¨¸ì‹  ë³µì¡ë„ ê³¼ë‹¤
   - 55ê°œ ìƒíƒœ, 16ê°œ Choice, 9ê°œ EventBridge
   - ë””ë²„ê¹… ë° ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€

3. **âš ï¸ MEDIUM**: ë°ì´í„° êµ¬ì¡° ë¶ˆì¼ì¹˜
   - execution_result vs parallel_results vs callback_result
   - Loop counter ì´ì¤‘ ê´€ë¦¬
   - S3 offload ë¡œì§ 4ê³³ ì¤‘ë³µ

### 9.2 ë¦¬íŒ©í† ë§ ìš°ì„ ìˆœìœ„

| ìš°ì„ ìˆœìœ„ | í•­ëª© | ì˜ˆìƒ ì‹œê°„ | ROI |
|---------|------|----------|-----|
| **P0** | Partition Map ìŠ¤í‚¤ë§ˆ í™•ì¥ | 1ì£¼ | ğŸ”¥ ë§¤ìš° ë†’ìŒ (í•µì‹¬ ê¸°ëŠ¥) |
| **P0** | ExecutionResult í‘œì¤€í™” | 1ì£¼ | ğŸ”¥ ë†’ìŒ (ì¼ê´€ì„±) |
| **P1** | ìƒíƒœ ë¨¸ì‹  ê°„ì†Œí™” | 2ì£¼ | ğŸ”¥ ë†’ìŒ (ìœ ì§€ë³´ìˆ˜) |
| **P1** | Loop Counter ë‹¨ì¼í™” | 1ì£¼ | ğŸ”¥ ì¤‘ê°„ (ì •í™•ì„±) |
| **P1** | Strategy ì„ íƒ ê°œì„  | 3ì¼ | ğŸ”¥ ì¤‘ê°„ (ì„±ëŠ¥) |
| **P2** | S3 Offload í—¬í¼ | 1ì¼ | ğŸ”¥ ë‚®ìŒ (ì½”ë“œ ì •ë¦¬) |
| **P2** | Partition Map ìºì‹± | 2ì¼ | ğŸ”¥ ì¤‘ê°„ (ì„±ëŠ¥) |
| **P2** | EventBridge â†’ SQS | 2ì¼ | ğŸ”¥ ë‚®ìŒ (ë¹„ìš© ì ˆê°) |

### 9.3 ê¶Œì¥ ì‹¤í–‰ ê³„íš

**ì¦‰ì‹œ ì‹œì‘ (ì´ë²ˆ ì£¼):**
- [ ] Partition Map ìŠ¤í‚¤ë§ˆ í™•ì¥ ì„¤ê³„
- [ ] Inter-segment edge ì •ë³´ ì¶”ì¶œ ë¡œì§ ì‘ì„±
- [ ] segment_runner HITP ê°ì§€ ë¡œì§ êµì²´

**ë‹¨ê¸° (2ì£¼ ë‚´):**
- [ ] ExecutionResult í‘œì¤€í™”
- [ ] SFN ResultPath í†µì¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ë° ë°°í¬

**ì¤‘ê¸° (1ê°œì›” ë‚´):**
- [ ] ìƒíƒœ ë¨¸ì‹  ê°„ì†Œí™” (55ê°œ â†’ 35ê°œ)
- [ ] Loop counter ë‹¨ì¼í™”
- [ ] Distributed strategy ê°œì„ 

**ì¥ê¸° (2ê°œì›” ë‚´):**
- [ ] ì„±ëŠ¥ ìµœì í™” (ìºì‹±, ë¹„ë™ê¸° ì²˜ë¦¬)
- [ ] ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
- [ ] ë¬¸ì„œí™” ë° ìš´ì˜ ê°€ì´ë“œ ì‘ì„±

---

**ìƒì„±ì¼**: 2026-01-29  
**ë²„ì „**: 1.0  
**ì‘ì„±ì**: Architecture Analysis Tool
