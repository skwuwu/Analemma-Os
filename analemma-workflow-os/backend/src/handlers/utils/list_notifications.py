"""
ì•Œë¦¼ ì„¼í„° (Notification Inbox) API

ì‚¬ìš©ìê°€ ì›¹ì‚¬ì´íŠ¸ ë°©ë¬¸ ì‹œ ë¯¸í™•ì¸ ì•Œë¦¼ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” Pull ë°©ì‹ API
í”„ë¡ íŠ¸ì—”ë“œ: GET /notifications?status=unread

[ë³€ê²½] Sparse Index íŒ¨í„´ ì ìš©
- Active Workflows: ExecutionsTableì˜ OwnerIdStatusIndexì—ì„œ ì¡°íšŒ
- Completed Workflows (Not Dismissed): ExecutionsTableì˜ NotificationsIndex GSIì—ì„œ ì¡°íšŒ
- ë‘ ê²°ê³¼ë¥¼ ë³‘í•©í•˜ì—¬ ë°˜í™˜
"""

import json
import os
import logging
import boto3
import base64
from decimal import Decimal
from botocore.exceptions import ClientError
from boto3.dynamodb.conditions import Key, Attr
from datetime import datetime

# ì•ˆì „í•œ ì„í¬íŠ¸ ì‹œë„
try:
    from src.common import statebag
except ImportError:
    try:
        from src.common import statebag
    except ImportError:
        statebag = None

# ê³µí†µ ëª¨ë“ˆì—ì„œ AWS í´ë¼ì´ì–¸íŠ¸ ë° ìœ í‹¸ë¦¬í‹° ê°€ì ¸ì˜¤ê¸°
try:
    from src.common.aws_clients import get_dynamodb_resource
    from src.common.json_utils import DecimalEncoder
    from src.common.http_utils import JSON_HEADERS
    dynamodb = get_dynamodb_resource()
    _USE_COMMON_UTILS = True
except ImportError:
    dynamodb = boto3.resource('dynamodb')
    _USE_COMMON_UTILS = False

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

EXECUTIONS_TABLE = os.environ.get('EXECUTIONS_TABLE')
# ğŸš¨ [Critical Fix] NotificationsIndex GSI ê¸°ë³¸ê°’ ì¶”ê°€
NOTIFICATIONS_INDEX = os.environ.get('NOTIFICATIONS_INDEX', 'NotificationsIndex')

# Fallback definitions if common modules not available
if not _USE_COMMON_UTILS:
    JSON_HEADERS = {"Content-Type": "application/json"}
    
    class DecimalEncoder(json.JSONEncoder):
        def default(self, obj):
            if isinstance(obj, Decimal):
                return int(obj) if obj % 1 == 0 else float(obj)
            if isinstance(obj, set):
                return list(obj)
            try:
                return super(DecimalEncoder, self).default(obj)
            except TypeError:
                return str(obj)


# =============================================================================
# [v2.3] Smart Grouping: ì•Œë¦¼ ìš°ì„ ìˆœìœ„ ì •ì˜
# PAUSED_FOR_HITP (ì‚¬ìš©ì ìŠ¹ì¸ ëŒ€ê¸°)ë¥¼ ìµœìƒë‹¨ì— ë°°ì¹˜í•˜ì—¬ ì—…ë¬´ ë³‘ëª© ì¦‰ì‹œ í•´ê²°
# =============================================================================
class NotificationPriority:
    """ì•Œë¦¼ ìš°ì„ ìˆœìœ„ (ìˆ«ìê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ìš°ì„ ìˆœìœ„)"""
    HITP_PAUSE = 0      # ì‚¬ìš©ì ìŠ¹ì¸ ëŒ€ê¸° - ìµœìš°ì„ 
    RUNNING = 1         # ì‹¤í–‰ ì¤‘
    COMPLETED = 2       # ì™„ë£Œë¨
    FAILED = 3          # ì‹¤íŒ¨
    DEFAULT = 10        # ê¸°íƒ€


def _get_priority(action: str, status: str) -> int:
    """ì•¡ì…˜/ìƒíƒœ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ê³„ì‚°."""
    if action == "hitp_pause" or status == "PAUSED_FOR_HITP":
        return NotificationPriority.HITP_PAUSE
    elif action == "execution_progress" or status in ("RUNNING", "STARTED"):
        return NotificationPriority.RUNNING
    elif status in ("SUCCEEDED", "COMPLETED"):
        return NotificationPriority.COMPLETED
    elif status == "FAILED":
        return NotificationPriority.FAILED
    return NotificationPriority.DEFAULT


def _extract_timestamp_safe(item: dict) -> int:
    """
    [v2.3] ì•ˆì •ì ì¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (UI í”Œë¦¬ì»¤ë§ ë°©ì§€).
    
    í´ë°± ìˆœì„œ:
    1. notificationTime
    2. startDate
    3. updated_at
    4. 0 (ë¦¬ìŠ¤íŠ¸ í•˜ë‹¨ì— ìœ„ì¹˜)
    
    datetime.now() ì‚¬ìš© ê¸ˆì§€ - ìƒˆë¡œê³ ì¹¨ë§ˆë‹¤ ìˆœì„œ ë³€ê²½ ë°©ì§€
    """
    # 1. notificationTime ì‹œë„
    notification_time = item.get('notificationTime')
    if notification_time:
        try:
            dt = datetime.fromisoformat(str(notification_time).replace('Z', '+00:00'))
            return int(dt.timestamp() * 1000)
        except (ValueError, AttributeError):
            pass
    
    # 2. startDate í´ë°± (boto3 datetime ë˜ëŠ” epoch ms)
    start_date = item.get('startDate')
    if start_date:
        try:
            if isinstance(start_date, datetime):
                return int(start_date.timestamp() * 1000)
            elif isinstance(start_date, (int, float)):
                # epoch msë¡œ ê°€ì •
                return int(start_date) if start_date > 1e12 else int(start_date * 1000)
            elif isinstance(start_date, str):
                dt = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
                return int(dt.timestamp() * 1000)
        except (ValueError, AttributeError):
            pass
    
    # 3. updated_at í´ë°±
    updated_at = item.get('updated_at') or item.get('updatedAt')
    if updated_at:
        try:
            if isinstance(updated_at, str):
                dt = datetime.fromisoformat(updated_at.replace('Z', '+00:00'))
                return int(dt.timestamp() * 1000)
        except (ValueError, AttributeError):
            pass
    
    # 4. íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ìŒ - 0ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ í•­ìƒ í•˜ë‹¨ ë°°ì¹˜
    return 0


def map_execution_to_notification(item):
    """
    ExecutionsTable ì•„ì´í…œì„ NotificationItem í˜•ì‹ìœ¼ë¡œ ë³€í™˜.
    
    [v2.3] ê°œì„ ì‚¬í•­:
    - ì•ˆì •ì ì¸ íƒ€ì„ìŠ¤íƒ¬í”„ í´ë°± (UI í”Œë¦¬ì»¤ë§ ë°©ì§€)
    - priority í•„ë“œ ì¶”ê°€ (Smart Grouping)
    """
    # [v2.3] ì•ˆì •ì ì¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
    ts = _extract_timestamp_safe(item)

    # Determine action based on status for frontend filtering
    status = item.get('status')
    action = "workflow_status"
    if status in ['RUNNING', 'STARTED']:
        action = "execution_progress"
    elif status == 'PAUSED_FOR_HITP':
        action = "hitp_pause"

    # [v2.3] Smart Groupingìš© ìš°ì„ ìˆœìœ„
    priority = _get_priority(action, status)

    return {
        "notificationId": item.get('executionArn'), # Use ARN as ID
        "type": "workflow_status",
        "action": action, # Top-level action for useNotifications hook
        "status": "sent", # Dismissë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ 'ë³´ì—¬ì§ˆ' ìƒíƒœ
        "timestamp": ts,
        "priority": priority,  # [v2.3] Smart Grouping
        "notification": {
            "type": "workflow_status",
            "payload": {
                "action": action, # Payload-level action for consistency
                "execution_id": item.get('executionArn'),
                "status": status,
                "workflowId": item.get('workflowId'),
                "start_time": item.get('startDate'),
                "stop_time": item.get('stopDate'),
                "message": f"Workflow {status}",
                # í•„ìš”í•œ ê²½ìš° output ë“± ì¶”ê°€
            }
        }
    }

def lambda_handler(event, context):
    """
    ì•Œë¦¼ ì„¼í„° API Lambda í•¸ë“¤ëŸ¬.
    
    [v2.3] ê°œì„ ì‚¬í•­:
    1. Active í•­ëª©ì—ë„ Limit ì ìš© (ë©”ëª¨ë¦¬ ë³´í˜¸)
    2. Smart Grouping: priority + timestamp ê¸°ë°˜ ì •ë ¬
    3. ë³µí•© í˜ì´ì§€ë„¤ì´ì…˜ í† í° (Active lastId + Completed LEK)
    """
    # 1. Auth & Setup
    try:
        owner_id = (event.get('requestContext', {})
                         .get('authorizer', {})
                         .get('jwt', {})
                         .get('claims', {})
                         .get('sub'))
    except Exception:
        owner_id = None
    
    if not owner_id:
        return {'statusCode': 401, 'headers': JSON_HEADERS, 'body': json.dumps({'error': 'Unauthorized'})}
    
    query_params = event.get('queryStringParameters') or {}
    
    # [v2.3] ì•ˆì „í•œ limit íŒŒì‹±
    try:
        limit = min(int(query_params.get('limit', 50)), 100)
    except (ValueError, TypeError):
        limit = 50
    
    next_token_in = query_params.get('nextToken')
    
    # [v2.3] ë³µí•© í† í° íŒŒì‹±
    active_last_id = None
    completed_lek = None
    if next_token_in:
        try:
            token_data = json.loads(base64.b64decode(next_token_in).decode('utf-8'))
            if isinstance(token_data, dict) and 'type' in token_data:
                # ë³µí•© í† í° í˜•ì‹
                active_last_id = token_data.get('active_last_id')
                completed_lek = token_data.get('completed_lek')
            else:
                # ë ˆê±°ì‹œ í˜•ì‹ (Completed LEKë§Œ)
                completed_lek = token_data
        except Exception:
            pass

    try:
        # 2. Fetch Active Notifications (ExecutionsTable OwnerIdStatusIndex)
        # [v2.3] Active í•­ëª©ì—ë„ Limit ì ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ë³´í˜¸
        active_items = []
        active_overflow = False  # ë” ë§ì€ Active í•­ëª© ì¡´ì¬ ì—¬ë¶€
        
        if EXECUTIONS_TABLE and os.environ.get('STATUS_INDEX'):
            status_index = os.environ.get('STATUS_INDEX')
            exec_table = dynamodb.Table(EXECUTIONS_TABLE)
            
            # [v2.3] PAUSED_FOR_HITPë¥¼ ìš°ì„  ì¡°íšŒ (Smart Grouping)
            priority_statuses = ['PAUSED_FOR_HITP', 'RUNNING', 'STARTED']
            active_limit_per_status = max(limit // len(priority_statuses), 10)
            
            for status in priority_statuses:
                if len(active_items) >= limit:
                    active_overflow = True
                    break
                    
                try:
                    resp = exec_table.query(
                        IndexName=status_index,
                        KeyConditionExpression=Key('ownerId').eq(owner_id) & Key('status').eq(status),
                        Limit=active_limit_per_status,  # [v2.3] ìƒíƒœë³„ Limit
                        ScanIndexForward=False  # ìµœì‹ ìˆœ
                    )
                    items = resp.get('Items', [])
                    mapped_items = [map_execution_to_notification(item) for item in items]
                    active_items.extend(mapped_items)
                    
                    if resp.get('LastEvaluatedKey'):
                        active_overflow = True
                        
                except Exception as e:
                    logger.error(f"Failed to query status {status}: {e}")
        
        # 3. Fetch Completed Notifications (ExecutionsTable GSI)
        completed_items = []
        completed_lek_out = None
        
        if EXECUTIONS_TABLE and NOTIFICATIONS_INDEX:
            exec_table = dynamodb.Table(EXECUTIONS_TABLE)
            
            # [v2.3] CompletedëŠ” Activeê°€ ì°¨ì§€í•œ ë§Œí¼ ì œì™¸í•˜ê³  ì¡°íšŒ
            completed_limit = max(limit - len(active_items), 10)
            
            query_kwargs = {
                'IndexName': NOTIFICATIONS_INDEX,
                'KeyConditionExpression': Key('ownerId').eq(owner_id),
                'ScanIndexForward': False,  # ìµœì‹ ìˆœ
                'Limit': completed_limit
            }
            
            if completed_lek:
                query_kwargs['ExclusiveStartKey'] = completed_lek

            exec_resp = exec_table.query(**query_kwargs)
            raw_completed = exec_resp.get('Items', [])
            completed_items = [map_execution_to_notification(item) for item in raw_completed]
            
            if exec_resp.get('LastEvaluatedKey'):
                completed_lek_out = exec_resp['LastEvaluatedKey']

        # 4. Merge & Deduplicate
        final_list = []
        seen_ids = set()
        
        # Active ë¨¼ì € ì¶”ê°€ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        for item in active_items:
            nid = item['notificationId']
            if nid not in seen_ids:
                final_list.append(item)
                seen_ids.add(nid)

        # Completed ì¶”ê°€
        for item in completed_items:
            nid = item['notificationId']
            if nid not in seen_ids:
                final_list.append(item)
                seen_ids.add(nid)

        # [v2.3] Smart Grouping: priority ìš°ì„ , ê°™ì€ ìš°ì„ ìˆœìœ„ ë‚´ì—ì„œ timestamp ë‚´ë¦¼ì°¨ìˆœ
        final_list.sort(key=lambda x: (x.get('priority', 10), -x.get('timestamp', 0)))
        
        # Slice to limit
        final_list = final_list[:limit]
        
        # [v2.3] ë³µí•© í˜ì´ì§€ë„¤ì´ì…˜ í† í° ìƒì„±
        next_token_out = None
        has_more = active_overflow or completed_lek_out is not None
        
        if has_more:
            # ë§ˆì§€ë§‰ Active ID ì¶”ì¶œ (ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ì¤‘ë³µ ë°©ì§€ìš©)
            last_active_id = None
            if final_list:
                active_in_result = [n for n in final_list if n.get('action') in ('execution_progress', 'hitp_pause')]
                if active_in_result:
                    last_active_id = active_in_result[-1].get('notificationId')
            
            composite_token = {
                'type': 'composite_v2',
                'active_last_id': last_active_id,
                'completed_lek': completed_lek_out
            }
            token_json = json.dumps(composite_token, cls=DecimalEncoder)
            next_token_out = base64.b64encode(token_json.encode('utf-8')).decode('utf-8')

        result = {
            'notifications': final_list,
            'count': len(final_list),
            'nextToken': next_token_out,
            'hasMore': has_more  # [v2.3] ì¶”ê°€ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€
        }

        return {
            'statusCode': 200,
            'headers': JSON_HEADERS,
            'body': json.dumps(result, cls=DecimalEncoder)
        }

    except Exception as e:
        logger.exception(f"Error fetching notifications: {e}")
        return {'statusCode': 500, 'headers': JSON_HEADERS, 'body': json.dumps({'error': str(e)})}
