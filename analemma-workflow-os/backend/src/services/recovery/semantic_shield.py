"""
ğŸ›¡ï¸ Semantic Shield â€” 3ë‹¨ê³„ ì£¼ì… íƒì§€ íŒŒì´í”„ë¼ì¸

ë¸”ë¡ë¦¬ìŠ¤íŠ¸(ì •ê·œì‹) ê¸°ë°˜ ë°©ì–´ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” ë‹¤ì¸µ ë°©ì–´:
  Stage 1: í…ìŠ¤íŠ¸ ì •ê·œí™” (Zero-Width SpaceÂ·RTLÂ·Base64Â·Homoglyph)
  Stage 2: ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­ (ì •ê·œí™” í›„ ì ìš© â†’ ì¸ì½”ë”© ìš°íšŒ ë¶ˆê°€)
  Stage 3: Semantic ë¶„ë¥˜ (ShieldGemma / Bedrock Guardrails, Ring 2+ ì „ìš©)

ê°€ë³€ì  ë°©ì–´ (ë¹„ìš© ìµœì í™”):
  Ring 0/1 (KERNEL/DRIVER): Stage 1+2ë§Œ ì‹¤í–‰ (ê³ ì‹ ë¢°, ëª¨ë¸ ì¶”ë¡  ìƒëµ)
  Ring 2/3 (SERVICE/USER) : Stage 1+2+3 ì „ì²´ (ShieldGemma í¬í•¨)

Author: Analemma OS Team
"""

import base64
import logging
import re
import unicodedata
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import List, Optional, Tuple, Dict, Any

from src.common.constants import SecurityConfig

logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ëª¨ë¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class DetectionType(Enum):
    ZERO_WIDTH_CHAR  = "zero_width_char"
    RTL_OVERRIDE     = "rtl_override"
    BASE64_INJECTION = "base64_injection"
    HOMOGLYPH        = "homoglyph"
    INJECTION_PATTERN = "injection_pattern"
    SEMANTIC_INJECTION = "semantic_injection"
    SEMANTIC_JAILBREAK = "semantic_jailbreak"


@dataclass
class Detection:
    detection_type: DetectionType
    description:    str
    stage:          int   # 1, 2, 3


@dataclass
class ShieldResult:
    allowed:         bool
    normalized_text: str
    detections:      List[Detection]
    risk_score:      float   # 0.0 â€“ 1.0
    stages_run:      int     # ì‹¤í–‰ëœ ë‹¨ê³„ ìˆ˜
    elapsed_ms:      float


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Homoglyph ë§¤í•‘ (Cyrillic Â· Greek Â· Full-width â†’ Latin)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_HOMOGLYPH_MAP: Dict[str, str] = {
    # Cyrillic
    'Ğ°': 'a', 'Ğµ': 'e', 'Ñ–': 'i', 'Ğ¾': 'o', 'Ñ€': 'p', 'Ñ': 'c',
    'Ñƒ': 'y', 'Ñ…': 'x', 'Ñ•': 's', 'Ô': 'd', 'É¡': 'g',
    # Greek
    'Î±': 'a', 'Î²': 'b', 'Î³': 'y', 'Î´': 'd', 'Îµ': 'e', 'Î¹': 'i',
    'Îº': 'k', 'Î¼': 'm', 'Î¿': 'o', 'Ï': 'p', 'Ïƒ': 's', 'Ï„': 't',
    'Ï…': 'u', 'Ï‡': 'x', 'Ï‰': 'w',
    # Full-width Latin (U+FF21â€“FF5A)
    'ï¼¡': 'A', 'ï¼¢': 'B', 'ï¼£': 'C', 'ï¼¤': 'D', 'ï¼¥': 'E',
    'ï¼¦': 'F', 'ï¼§': 'G', 'ï¼¨': 'H', 'ï¼©': 'I', 'ï¼ª': 'J',
    'ï½': 'a', 'ï½‚': 'b', 'ï½ƒ': 'c', 'ï½„': 'd', 'ï½…': 'e',
    'ï½†': 'f', 'ï½‡': 'g', 'ï½ˆ': 'h', 'ï½‰': 'i', 'ï½Š': 'j',
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Stage 1: Normalization Pipeline
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class NormalizationPipeline:
    """
    í…ìŠ¤íŠ¸ ì •ê·œí™” â€” ì¸ì½”ë”©Â·ìœ ë‹ˆì½”ë“œ ìš°íšŒ ê¸°ë²• ì œê±°.
    ì •ê·œí™” ê²°ê³¼(íƒì§€ ë‚´ìš© í¬í•¨)ë¥¼ Stage 2 íŒ¨í„´ ë§¤ì¹­ì— ì „ë‹¬.
    """

    ZERO_WIDTH = frozenset({'\u200b', '\u200c', '\u200d', '\ufeff', '\u2060'})
    RTL_OVERRIDE = frozenset({'\u202e', '\u202d', '\u200f', '\u200e'})

    # Base64 í›„ë³´: 20ì ì´ìƒì˜ ìœ íš¨í•œ Base64 ë¬¸ìì—´
    _BASE64_PATTERN = re.compile(r'[A-Za-z0-9+/]{20,}={0,2}', re.ASCII)

    # Base64 ë””ì½”ë”© í›„ ì£¼ì… í‚¤ì›Œë“œ (ì†Œë¬¸ì)
    _INJECTION_KEYWORDS = frozenset({
        'ignore', 'disregard', 'forget', 'override', 'jailbreak',
        'system:', 'bypass', 'escape', 'you are now',
        'ì´ì „ ì§€ì‹œ', 'ë¬´ì‹œ', 'ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸',
    })

    def normalize(self, text: str) -> Tuple[str, List[Detection]]:
        """
        ì •ê·œí™” ìˆ˜í–‰.

        Returns:
            (ì •ê·œí™”ëœ í…ìŠ¤íŠ¸, íƒì§€ ëª©ë¡)
        """
        detections: List[Detection] = []
        result = text

        # 1-a. Zero-Width Space / BOM ì œê±°
        if any(c in self.ZERO_WIDTH for c in result):
            result = ''.join(c for c in result if c not in self.ZERO_WIDTH)
            detections.append(Detection(
                detection_type=DetectionType.ZERO_WIDTH_CHAR,
                description="Zero-Width Space / BOM characters stripped",
                stage=1,
            ))

        # 1-b. RTL Override ì œê±°
        if any(c in self.RTL_OVERRIDE for c in result):
            result = ''.join(c for c in result if c not in self.RTL_OVERRIDE)
            detections.append(Detection(
                detection_type=DetectionType.RTL_OVERRIDE,
                description="RTL override characters stripped",
                stage=1,
            ))

        # 1-c. Base64 ë””ì½”ë“œ ì‹œë„
        b64_detections = self._check_base64(result)
        detections.extend(b64_detections)

        # 1-d. Unicode NFC ì •ê·œí™”
        result = unicodedata.normalize('NFC', result)

        # 1-e. Homoglyph ì •ê·œí™”
        result, hg_detections = self._normalize_homoglyphs(result)
        detections.extend(hg_detections)

        return result, detections

    def _check_base64(self, text: str) -> List[Detection]:
        """Base64 ì¸ì½”ë”©ëœ ì£¼ì… ì‹œë„ íƒì§€."""
        detections = []
        for match in self._BASE64_PATTERN.finditer(text):
            b64_str = match.group(0)
            try:
                decoded = base64.b64decode(b64_str + '==').decode('utf-8', errors='ignore')
                decoded_lower = decoded.lower()
                if any(kw in decoded_lower for kw in self._INJECTION_KEYWORDS):
                    detections.append(Detection(
                        detection_type=DetectionType.BASE64_INJECTION,
                        description=f"Base64-encoded injection: {decoded[:80]}",
                        stage=1,
                    ))
            except Exception:
                pass
        return detections

    def _normalize_homoglyphs(self, text: str) -> Tuple[str, List[Detection]]:
        """Homoglyph(ë™í˜•ì´ì˜ì) ì •ê·œí™”."""
        detections = []
        result = []
        replaced = False

        for char in text:
            rep = _HOMOGLYPH_MAP.get(char)
            if rep:
                result.append(rep)
                replaced = True
            else:
                result.append(char)

        if replaced:
            detections.append(Detection(
                detection_type=DetectionType.HOMOGLYPH,
                description="Homoglyph chars normalized (Cyrillic/Greek/Full-width â†’ Latin)",
                stage=1,
            ))

        return ''.join(result), detections


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Stage 2: í•œêµ­ì–´ ì£¼ì… íŒ¨í„´
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_KOREAN_INJECTION_PATTERNS: List[re.Pattern] = [
    re.compile(r'ì´ì „\s*(ì§€ì‹œì‚¬í•­|ëª…ë ¹|ì¸ìŠ¤íŠ¸ëŸ­ì…˜)\s*(ë¬´ì‹œ|ì‚­ì œ|ìŠì–´)', re.IGNORECASE),
    re.compile(r'ì‹œìŠ¤í…œ\s*í”„ë¡¬í”„íŠ¸\s*(ê³µê°œ|ì¶œë ¥|ëˆ„ì„¤)', re.IGNORECASE),
    re.compile(r'ì—­í• \s*(ë³€ê²½|êµì²´|ë¬´ì‹œ)', re.IGNORECASE),
    re.compile(r'ìƒˆë¡œìš´\s*(ì—­í• |í˜ë¥´ì†Œë‚˜|ì¸ê²©)', re.IGNORECASE),
    re.compile(r'ë³´ì•ˆ\s*(ìš°íšŒ|ë¬´ë ¥í™”|ë¹„í™œì„±í™”)', re.IGNORECASE),
    re.compile(r'(ê´€ë¦¬ì|admin|root)\s*(ê¶Œí•œ|ëª¨ë“œ|ì ‘ê·¼)', re.IGNORECASE),
    re.compile(r'ì§€ê¸ˆë¶€í„°\s*(ë‹¤ë¥¸|ìƒˆë¡œìš´)\s*(ì—­í• |ëª¨ë“œ)', re.IGNORECASE),
    re.compile(r'(ì´ì „|ìœ„)\s*(ëª¨ë“ )?\s*(ëª…ë ¹|ì§€ì‹œ)\s*(ì‚­ì œ|ë¬´ì‹œ)', re.IGNORECASE),
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SemanticShield â€” í†µí•© íŒŒì´í”„ë¼ì¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class SemanticShield:
    """
    3ë‹¨ê³„ Semantic Shield.

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Stage 1  NormalizationPipeline               â”‚  (ëª¨ë“  Ring)
    â”‚ Stage 2  Pattern Matching (EN + KO)          â”‚  (ëª¨ë“  Ring)
    â”‚ Stage 3  Semantic Classifier (LLM)           â”‚  (Ring 2/3ë§Œ)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ì°¨ë‹¨ íŒì •:
      BASE64_INJECTION, INJECTION_PATTERN, SEMANTIC_* â†’ ì°¨ë‹¨
      ZERO_WIDTH_CHAR, RTL_OVERRIDE, HOMOGLYPH       â†’ ì •ê·œí™” í›„ í—ˆìš©
    """

    _instance: Optional['SemanticShield'] = None

    # ì°¨ë‹¨ ìœ ë°œ DetectionType
    _BLOCKING_TYPES = frozenset({
        DetectionType.BASE64_INJECTION,
        DetectionType.INJECTION_PATTERN,
        DetectionType.SEMANTIC_INJECTION,
        DetectionType.SEMANTIC_JAILBREAK,
    })

    # ìœ„í—˜ë„ ê°€ì¤‘ì¹˜
    _TYPE_RISK = {
        DetectionType.ZERO_WIDTH_CHAR:    0.2,
        DetectionType.RTL_OVERRIDE:       0.2,
        DetectionType.HOMOGLYPH:          0.3,
        DetectionType.BASE64_INJECTION:   0.9,
        DetectionType.INJECTION_PATTERN:  0.7,
        DetectionType.SEMANTIC_INJECTION: 0.95,
        DetectionType.SEMANTIC_JAILBREAK: 1.0,
    }
    _STAGE_WEIGHT = {1: 0.3, 2: 0.5, 3: 0.8}

    def __init__(self, llm_client=None):
        self.normalizer = NormalizationPipeline()
        self.llm_client = llm_client
        self._compiled_english = [
            re.compile(p) for p in SecurityConfig.INJECTION_PATTERNS
        ]

    @classmethod
    def get_instance(cls, llm_client=None) -> 'SemanticShield':
        """ì‹±ê¸€í†¤ (Double-checked locking)."""
        if cls._instance is None:
            cls._instance = cls(llm_client=llm_client)
        return cls._instance

    def inspect(self, text: str, ring_level: int) -> ShieldResult:
        """
        3ë‹¨ê³„ ë³´ì•ˆ ê²€ì‚¬.

        Args:
            text:       ê²€ì‚¬í•  ì›ë³¸ í…ìŠ¤íŠ¸
            ring_level: RingLevel.value (ì •ìˆ˜: 0â€“3)

        Returns:
            ShieldResult
        """
        start = time.time()
        all_detections: List[Detection] = []

        # Stage 1: ì •ê·œí™”
        normalized, stage1 = self.normalizer.normalize(text)
        all_detections.extend(stage1)

        # Stage 2: íŒ¨í„´ ë§¤ì¹­ (ì •ê·œí™” í›„ í…ìŠ¤íŠ¸ì— ì ìš©)
        stage2 = self._pattern_match(normalized)
        all_detections.extend(stage2)

        stages_run = 2

        # Stage 3: Semantic ë¶„ë¥˜ (Ring 2/3ë§Œ, LLM í´ë¼ì´ì–¸íŠ¸ ì¡´ì¬ ì‹œ)
        if ring_level >= 2 and self.llm_client:
            try:
                stage3 = self._semantic_classify(normalized)
                all_detections.extend(stage3)
                stages_run = 3
            except Exception as e:
                logger.warning(
                    f"[SemanticShield] Stage 3 failed, degraded to Stage 2: {e}"
                )

        risk_score = self._calculate_risk(all_detections)
        allowed = not any(d.detection_type in self._BLOCKING_TYPES for d in all_detections)
        elapsed_ms = (time.time() - start) * 1000

        if all_detections:
            logger.warning(
                "[SemanticShield] ring=%d stages=%d allowed=%s risk=%.2f detections=%s",
                ring_level, stages_run, allowed, risk_score,
                [d.detection_type.value for d in all_detections],
            )

        return ShieldResult(
            allowed=allowed,
            normalized_text=normalized,
            detections=all_detections,
            risk_score=risk_score,
            stages_run=stages_run,
            elapsed_ms=elapsed_ms,
        )

    # â”€â”€ Stage 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _pattern_match(self, normalized_text: str) -> List[Detection]:
        """ì˜ì–´ + í•œêµ­ì–´ íŒ¨í„´ ë§¤ì¹­ (ì •ê·œí™” í…ìŠ¤íŠ¸ ê¸°ì¤€)."""
        detections = []

        for pattern in self._compiled_english:
            if pattern.search(normalized_text):
                detections.append(Detection(
                    detection_type=DetectionType.INJECTION_PATTERN,
                    description=f"EN injection pattern: {pattern.pattern[:60]}",
                    stage=2,
                ))

        for pattern in _KOREAN_INJECTION_PATTERNS:
            if pattern.search(normalized_text):
                detections.append(Detection(
                    detection_type=DetectionType.INJECTION_PATTERN,
                    description=f"KO injection pattern: {pattern.pattern[:60]}",
                    stage=2,
                ))

        return detections

    # â”€â”€ Stage 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _semantic_classify(self, text: str) -> List[Detection]:
        """
        LLM ê¸°ë°˜ Semantic ë¶„ë¥˜.
        Bedrock Guardrails API ë˜ëŠ” Gemini ShieldGemma í˜¸ì¶œ.
        """
        detections = []

        try:
            # Bedrock Guardrails ApplyGuardrail API
            if hasattr(self.llm_client, 'apply_guardrail'):
                result = self.llm_client.apply_guardrail(
                    guardrailIdentifier='analemma-injection-guard',
                    guardrailVersion='DRAFT',
                    source='INPUT',
                    content=[{'text': {'text': text}}],
                )
                if result.get('action') == 'GUARDRAIL_INTERVENED':
                    for assessment in result.get('assessments', []):
                        if assessment.get('promptAttack', {}).get('attackDetected'):
                            detections.append(Detection(
                                detection_type=DetectionType.SEMANTIC_INJECTION,
                                description="Bedrock Guardrails: prompt attack detected",
                                stage=3,
                            ))

            # Gemini ShieldGemma (classify_safety ì¸í„°í˜ì´ìŠ¤)
            elif hasattr(self.llm_client, 'classify_safety'):
                result = self.llm_client.classify_safety(text)
                for category, score in result.items():
                    if 'INJECTION' in category.upper() and score > 0.7:
                        detections.append(Detection(
                            detection_type=DetectionType.SEMANTIC_INJECTION,
                            description=f"ShieldGemma: {category} score={score:.2f}",
                            stage=3,
                        ))
                    elif 'JAILBREAK' in category.upper() and score > 0.7:
                        detections.append(Detection(
                            detection_type=DetectionType.SEMANTIC_JAILBREAK,
                            description=f"ShieldGemma: {category} score={score:.2f}",
                            stage=3,
                        ))

        except Exception as e:
            logger.debug(f"[SemanticShield] Stage 3 classify error: {e}")

        return detections

    # â”€â”€ ìœ„í—˜ë„ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _calculate_risk(self, detections: List[Detection]) -> float:
        """íƒì§€ ê²°ê³¼ ê¸°ë°˜ ìœ„í—˜ë„ ì ìˆ˜ (0.0â€“1.0)."""
        if not detections:
            return 0.0

        max_risk = 0.0
        for d in detections:
            type_w = self._TYPE_RISK.get(d.detection_type, 0.5)
            stage_w = self._STAGE_WEIGHT.get(d.stage, 0.5)
            max_risk = max(max_risk, type_w * stage_w)

        return min(1.0, max_risk)
