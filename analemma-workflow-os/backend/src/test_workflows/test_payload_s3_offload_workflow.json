{
    "workflow_name": "Payload S3 Offload Test",
    "description": "StateDataManager S3 오프로딩 기능 테스트 - 대용량 필드 자동 S3 저장 검증",
    "nodes": [
        {
            "id": "s3_offload_prep",
            "type": "operator",
            "config": {
                "code": "print('S3 오프로딩 테스트 준비')\nstate['s3_offload_test_started'] = True\n# S3 오프로딩을 트리거할 대용량 context 데이터 생성\nlarge_context = 'LARGE_CONTEXT_DATA_FOR_S3_OFFLOAD_' * 3000  # ~120KB context\nstate['context'] = large_context\nstate['context_size_kb'] = len(large_context) / 1024\n\n# [v1.0.1] 역직렬화 복구 테스트를 위한 원본 데이터 fingerprint 저장\nstate['_original_context_fingerprint'] = {\n    'first_50_chars': large_context[:50],\n    'last_50_chars': large_context[-50:],\n    'total_length': len(large_context),\n    'hash_sample': hash(large_context[:1000]) % 10000000  # 샘플 해시\n}\n\nresult = {\n    'test_type': 'payload_s3_offload',\n    'context_size_kb': state['context_size_kb'],\n    'should_trigger_s3_offload': state['context_size_kb'] > 50,  # 50KB 임계값\n    'field_name': 'context',\n    'fingerprint_saved': True\n}\nstate['prep_result'] = result\nprint('S3 오프로딩 테스트 데이터 생성: context ' + str(round(state['context_size_kb'], 1)) + 'KB (임계값: 50KB)')\nprint('Fingerprint 저장됨: first_50=' + large_context[:30] + '...')",
                "output_key": "prep_result"
            }
        },
        {
            "id": "s3_offload_llm_responses",
            "type": "operator",
            "config": {
                "code": "print('S3 오프로딩용 LLM 응답 데이터 생성')\nif state.get('s3_offload_test_started'):\n    # 대용량 LLM 응답 시뮬레이션\n    large_llm_responses = {\n        'response_1': 'LLM_RESPONSE_DATA_PATTERN_' * 2000,  # ~60KB\n        'response_2': 'ANOTHER_LLM_RESPONSE_PATTERN_' * 1500,  # ~45KB\n        'response_3': 'FINAL_LLM_RESPONSE_PATTERN_' * 1000   # ~30KB\n    }\n    state['llm_responses'] = large_llm_responses\n    \n    # 각 응답 크기 계산\n    response_sizes = {k: len(v) / 1024 for k, v in large_llm_responses.items()}\n    total_llm_size_kb = sum(response_sizes.values())\n    state['llm_responses_size_kb'] = total_llm_size_kb\n    \n    # [v1.0.1] LLM 응답 fingerprint 저장\n    state['_original_llm_fingerprint'] = {\n        'response_1_last_30': large_llm_responses['response_1'][-30:],\n        'response_count': len(large_llm_responses),\n        'total_size_kb': total_llm_size_kb\n    }\n    \n    result = {\n        'status': 'llm_responses_generated',\n        'response_sizes_kb': response_sizes,\n        'total_llm_size_kb': total_llm_size_kb,\n        'should_offload_llm_responses': total_llm_size_kb > 50,\n        'fingerprint_saved': True\n    }\n    state['llm_result'] = result\n    print('LLM 응답 데이터 생성: 총 ' + str(round(total_llm_size_kb, 1)) + 'KB')\nelse:\n    raise RuntimeError('S3 오프로딩 테스트 준비가 되지 않음')",
                "output_key": "llm_result"
            }
        },
        {
            "id": "s3_offload_generated_content",
            "type": "operator",
            "config": {
                "code": "print('S3 오프로딩용 생성 콘텐츠 데이터 생성')\nif state.get('s3_offload_test_started'):\n    # 대용량 생성 콘텐츠 시뮬레이션\n    large_generated_content = {\n        'document': 'GENERATED_DOCUMENT_CONTENT_' * 4000,  # ~120KB\n        'summary': 'GENERATED_SUMMARY_CONTENT_' * 1000,   # ~30KB\n        'analysis': 'GENERATED_ANALYSIS_CONTENT_' * 2000  # ~60KB\n    }\n    state['generated_content'] = large_generated_content\n    \n    # 생성 콘텐츠 크기 계산\n    content_sizes = {k: len(v) / 1024 for k, v in large_generated_content.items()}\n    total_content_size_kb = sum(content_sizes.values())\n    state['generated_content_size_kb'] = total_content_size_kb\n    \n    # 전체 페이로드 크기 계산\n    total_payload_kb = (\n        state.get('context_size_kb', 0) + \n        state.get('llm_responses_size_kb', 0) + \n        total_content_size_kb\n    )\n    state['total_payload_size_kb'] = total_payload_kb\n    \n    # [v1.0.1] 생성 콘텐츠 fingerprint 저장\n    state['_original_content_fingerprint'] = {\n        'document_last_30': large_generated_content['document'][-30:],\n        'content_count': len(large_generated_content),\n        'total_size_kb': total_content_size_kb\n    }\n    \n    result = {\n        'status': 'generated_content_created',\n        'content_sizes_kb': content_sizes,\n        'total_content_size_kb': total_content_size_kb,\n        'total_payload_size_kb': total_payload_kb,\n        'multiple_fields_need_offload': True,\n        'fingerprint_saved': True\n    }\n    state['content_result'] = result\n    print('생성 콘텐츠 데이터 생성: 총 ' + str(round(total_content_size_kb, 1)) + 'KB, 전체 페이로드: ' + str(round(total_payload_kb, 1)) + 'KB')\nelse:\n    raise RuntimeError('S3 오프로딩 테스트 준비가 되지 않음')",
                "output_key": "content_result"
            }
        },
        {
            "id": "s3_offload_validator",
            "type": "operator",
            "config": {
                "code": "print('S3 오프로딩 테스트 검증 시작')\n\n# ============================================================\n# [v1.0.1] 포인터 변환 검증 (Pointer Conversion Verification)\n# ============================================================\nprint('\\n[1/3] 포인터 변환 검증...')\n\npointer_verification = {\n    'context': {'checked': False, 'is_pointer': False, 'pointer_type': None},\n    'llm_responses': {'checked': False, 'is_pointer': False, 'pointer_type': None},\n    'generated_content': {'checked': False, 'is_pointer': False, 'pointer_type': None}\n}\n\n# context 필드 포인터 검증\ncontext_val = state.get('context')\nif context_val is not None:\n    pointer_verification['context']['checked'] = True\n    # 커널 로직상 오프로딩되면 s3:// URL 또는 dict(포인터 객체)로 변함\n    if isinstance(context_val, str) and context_val.startswith('s3://'):     \n        pointer_verification['context']['is_pointer'] = True\n        pointer_verification['context']['pointer_type'] = 's3_url'\n        print('  context: S3 URL 포인터로 변환됨 - ' + context_val[:80] + '...')\n    elif isinstance(context_val, dict) and '_s3_ref' in str(context_val):     \n        pointer_verification['context']['is_pointer'] = True\n        pointer_verification['context']['pointer_type'] = 's3_ref_object'\n        print('  context: S3 참조 객체로 변환됨')\n    else:\n        pointer_verification['context']['pointer_type'] = 'raw_data'\n        print('  context: 원본 데이터 유지 (Hydration 완료 또는 오프로딩 미발생)')\n\n# llm_responses 필드 포인터 검증\nllm_val = state.get('llm_responses')\nif llm_val is not None:\n    pointer_verification['llm_responses']['checked'] = True\n    if isinstance(llm_val, str) and llm_val.startswith('s3://'):     \n        pointer_verification['llm_responses']['is_pointer'] = True\n        pointer_verification['llm_responses']['pointer_type'] = 's3_url'\n    elif isinstance(llm_val, dict) and '_s3_ref' in str(llm_val):     \n        pointer_verification['llm_responses']['is_pointer'] = True\n        pointer_verification['llm_responses']['pointer_type'] = 's3_ref_object'\n    else:\n        pointer_verification['llm_responses']['pointer_type'] = 'raw_data'\n    print('  llm_responses: ' + pointer_verification['llm_responses']['pointer_type'])\n\n# generated_content 필드 포인터 검증\ncontent_val = state.get('generated_content')\nif content_val is not None:\n    pointer_verification['generated_content']['checked'] = True\n    if isinstance(content_val, str) and content_val.startswith('s3://'):     \n        pointer_verification['generated_content']['is_pointer'] = True\n        pointer_verification['generated_content']['pointer_type'] = 's3_url'\n    elif isinstance(content_val, dict) and '_s3_ref' in str(content_val):     \n        pointer_verification['generated_content']['is_pointer'] = True\n        pointer_verification['generated_content']['pointer_type'] = 's3_ref_object'\n    else:\n        pointer_verification['generated_content']['pointer_type'] = 'raw_data'\n    print('  generated_content: ' + pointer_verification['generated_content']['pointer_type'])\n\n# ============================================================\n# [v1.0.1] 역직렬화(Hydration) 복구 테스트\n# ============================================================\nprint('\\n[2/3] 역직렬화 복구 테스트...')\n\nhydration_verification = {\n    'context_hydrated': False,\n    'data_integrity_verified': False,\n    'first_chars_match': False,\n    'last_chars_match': False,\n    'length_match': False\n}\n\noriginal_fingerprint = state.get('_original_context_fingerprint', {})\ncontext_data = state.get('context')\n\n# context가 원본 데이터로 복구되었는지 확인 (포인터가 아닌 실제 문자열인지)\nif isinstance(context_data, str) and not context_data.startswith('s3://'):     \n    hydration_verification['context_hydrated'] = True\n    \n    # 원본 fingerprint와 비교하여 데이터 무결성 검증\n    if original_fingerprint:\n        # 첫 50자 일치 확인\n        orig_first = original_fingerprint.get('first_50_chars', '')\n        if context_data[:50] == orig_first:\n            hydration_verification['first_chars_match'] = True\n            print('  First 50 chars: MATCH')\n        else:\n            print('  First 50 chars: MISMATCH')\n            print('    Expected: ' + orig_first[:30] + '...')\n            print('    Actual: ' + context_data[:30] + '...')\n        \n        # 마지막 50자 일치 확인 (중요: 데이터 손실/절단 감지)\n        orig_last = original_fingerprint.get('last_50_chars', '')\n        if context_data[-50:] == orig_last:\n            hydration_verification['last_chars_match'] = True\n            print('  Last 50 chars: MATCH')\n        else:\n            print('  Last 50 chars: MISMATCH')\n            print('    Expected: ...' + orig_last[-30:])\n            print('    Actual: ...' + context_data[-30:])\n        \n        # 길이 일치 확인\n        orig_len = original_fingerprint.get('total_length', 0)\n        if len(context_data) == orig_len:\n            hydration_verification['length_match'] = True\n            print('  Length: MATCH (' + str(len(context_data)) + ' chars)')\n        else:\n            print('  Length: MISMATCH (Expected: ' + str(orig_len) + ', Actual: ' + str(len(context_data)) + ')')\n        \n        # 전체 무결성 판정\n        hydration_verification['data_integrity_verified'] = (\n            hydration_verification['first_chars_match'] and\n            hydration_verification['last_chars_match'] and\n            hydration_verification['length_match']\n        )\n    else:\n        print('  WARNING: Original fingerprint not found, skipping integrity check')\nelse:\n    print('  context is still a pointer or missing, hydration may not have occurred')\n\n# ============================================================\n# [3/3] 기존 검증 조건들\n# ============================================================\nprint('\\n[3/3] 기본 조건 검증...')\n\nsuccess_conditions = [\n    state.get('s3_offload_test_started') == True,\n    state.get('context_size_kb', 0) > 50,\n    state.get('llm_responses_size_kb', 0) > 50,\n    state.get('generated_content_size_kb', 0) > 50,\n    state.get('total_payload_size_kb', 0) > 200,\n    'context' in state,\n    'llm_responses' in state,\n    'generated_content' in state,\n    'prep_result' in state,\n    'llm_result' in state,\n    'content_result' in state\n]\n\n# [v1.0.1] 추가 검증 조건\nkernel_level_conditions = [\n    pointer_verification['context']['checked'],\n    pointer_verification['llm_responses']['checked'],\n    pointer_verification['generated_content']['checked'],\n    hydration_verification['context_hydrated'],\n    hydration_verification['data_integrity_verified']\n]\n\nall_basic_passed = all(success_conditions)\nall_kernel_passed = all(kernel_level_conditions)\ntotal_size = state.get('total_payload_size_kb', 0)\n\nfields_to_offload = []\nif state.get('context_size_kb', 0) > 50:\n    fields_to_offload.append('context')\nif state.get('llm_responses_size_kb', 0) > 50:\n    fields_to_offload.append('llm_responses')\nif state.get('generated_content_size_kb', 0) > 50:\n    fields_to_offload.append('generated_content')\n\nprint('\\n[RESULTS]')\nprint('  Basic conditions: ' + str(sum(success_conditions)) + '/' + str(len(success_conditions)) + ' passed')\nprint('  Kernel-level conditions: ' + str(sum(kernel_level_conditions)) + '/' + str(len(kernel_level_conditions)) + ' passed')\nprint('  Total payload: ' + str(round(total_size, 1)) + 'KB')\nprint('  Fields to offload: ' + str(fields_to_offload))\n\n# 최종 판정\nif all_basic_passed and all_kernel_passed:\n    state['TEST_RESULT'] = 'SUCCESS: S3 오프로딩+역직렬화 검증 성공 - ' + str(round(total_size, 1)) + 'KB, 무결성 OK'\n    state['VALIDATION_STATUS'] = 'PASSED'\n    print('\\nS3 오프로딩 테스트 검증 성공 (포인터 변환 + 역직렬화 복구 확인됨)')\nelif all_basic_passed and not all_kernel_passed:\n    state['TEST_RESULT'] = 'PARTIAL: 기본 조건 통과, 커널 레벨 검증 부분 실패'\n    state['VALIDATION_STATUS'] = 'PARTIAL'\n    print('\\nS3 오프로딩 테스트 부분 성공 (커널 레벨 검증 추가 필요)')\nelse:\n    state['TEST_RESULT'] = 'FAILURE: S3 오프로딩 테스트 실패 - ' + str(round(total_size, 1)) + 'KB'\n    state['VALIDATION_STATUS'] = 'FAILED'\n    print('\\nS3 오프로딩 테스트 검증 실패')\n\nstate['validation_details'] = {\n    'test_type': 'payload_s3_offload',\n    'version': '1.0.1',\n    'total_payload_size_kb': total_size,\n    'context_size_kb': state.get('context_size_kb', 0),\n    'llm_responses_size_kb': state.get('llm_responses_size_kb', 0),\n    'generated_content_size_kb': state.get('generated_content_size_kb', 0),\n    'fields_to_offload': fields_to_offload,\n    'offload_threshold_kb': 50,\n    'basic_conditions': {'checked': len(success_conditions), 'passed': sum(success_conditions)},\n    'kernel_level_conditions': {'checked': len(kernel_level_conditions), 'passed': sum(kernel_level_conditions)},\n    'pointer_verification': pointer_verification,\n    'hydration_verification': hydration_verification\n}"
            }
        }
    ],
    "edges": [
        {
            "source": "s3_offload_prep",
            "target": "s3_offload_llm_responses",
            "type": "normal"
        },
        {
            "source": "s3_offload_llm_responses",
            "target": "s3_offload_generated_content",
            "type": "normal"
        },
        {
            "source": "s3_offload_generated_content",
            "target": "s3_offload_validator",
            "type": "normal"
        }
    ],
    "start_node": "s3_offload_prep"
}