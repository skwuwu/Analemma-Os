{
  "id": "COST_OPTIMIZED_PARALLEL_TEST",
  "name": "Cost Optimized Parallel Scheduler Test",
  "description": "[Enhanced] COST_OPTIMIZED 전략 + 배치 분할 검증 + 토큰 스트레스 테스트",
  "version": "1.0.1",
  "test_category": "cost_guardrail",
  "nodes": [
    {
      "id": "setup",
      "type": "operator",
      "label": "테스트 설정",
      "config": {
        "language": "python",
        "code": "# 20개 문서 (각 1000 토큰 추정 = 20,000 토큰)\nstate['documents'] = [f'Long document content {i} ' * 150 for i in range(20)]\n# 50개 쿼리 (각 100 토큰 추정 = 5,000 토큰)\nstate['queries'] = [f'Complex query {i} ' * 10 for i in range(50)]\nstate['setup_complete'] = True\nprint(f'Setup: {len(state[\"documents\"])} documents (20k tokens), {len(state[\"queries\"])} queries (5k tokens)')"
      }
    },
    {
      "id": "cost_aware_parallel",
      "type": "parallel_group",
      "label": "비용 인지 병렬 그룹 (토큰 스트레스)",
      "resource_policy": {
        "max_concurrent_memory_mb": 2048,
        "max_concurrent_tokens": 10000,
        "max_concurrent_branches": 5,
        "strategy": "COST_OPTIMIZED"
      },
      "branches": [
        {
          "id": "branch_doc_summarize",
          "name": "문서 요약 (토큰 Heavy)",
          "nodes": [
            {
              "id": "doc_foreach",
              "type": "for_each",
              "config": {
                "input_list_key": "documents",
                "output_key": "summaries",
                "sub_node_config": {
                  "nodes": [
                    {
                      "id": "summarize_llm",
                      "type": "llm_chat",
                      "config": {
                        "model": "gemini-2.0-flash",
                        "prompt_template": "Summarize: {{item}}",
                        "output_key": "summary"
                      }
                    }
                  ],
                  "edges": []
                }
              }
            }
          ],
          "edges": []
        },
        {
          "id": "branch_query_process",
          "name": "쿼리 처리 (토큰 Medium)",
          "nodes": [
            {
              "id": "query_llm",
              "type": "llm_chat",
              "config": {
                "model": "gemini-2.0-flash",
                "prompt_template": "Process queries: {{queries}}",
                "output_key": "query_results"
              }
            }
          ],
          "edges": []
        },
        {
          "id": "branch_light_calc",
          "name": "경량 계산",
          "nodes": [
            {
              "id": "calc_code",
              "type": "operator",
              "config": {
                "language": "python",
                "code": "state['calc_result'] = sum(range(1000))"
              }
            }
          ],
          "edges": []
        }
      ]
    },
    {
      "id": "verify",
      "type": "operator",
      "label": "[Critical] 배치 분할 검증",
      "config": {
        "language": "python",
        "code": "import json\n\nprint('[COST_OPTIMIZED VERIFICATION] Checking batch split results')\n\n# ① scheduling_metadata 추출\nmetadata = state.get('scheduling_metadata', {})\nbatch_count = metadata.get('batch_count', 0)\nstrategy = metadata.get('strategy', '')\ntotal_tokens = metadata.get('total_tokens', 0)\nbatch_splits = metadata.get('batch_splits', [])\n\nprint(f'Metadata: {json.dumps(metadata, indent=2)}')\n\n# ② 예상 검증: 토큰 제한(10000) vs 실제 부하(25,000)\n# 25,000 / 10,000 = 2.5 -> 최소 3개 배치 필요\nexpected_min_batches = 3  # 여유 있게 3개 설정\n\nchecks = [\n    strategy == 'COST_OPTIMIZED',\n    batch_count >= expected_min_batches,\n    total_tokens > 20000,  # 최소 20k 토큰 확인\n    isinstance(batch_splits, list),\n    len(batch_splits) >= 1\n]\n\nall_passed = all(checks)\n\nprint(f'Strategy: {strategy} (expected: COST_OPTIMIZED)')\nprint(f'Batch Count: {batch_count} (expected: >={expected_min_batches})')\nprint(f'Total Tokens: {total_tokens} (expected: >20000)')\nprint(f'Batch Splits: {len(batch_splits)} batches')\nprint(f'All checks passed: {all_passed}')\n\nstate['cost_test_complete'] = True\nstate['branch_count'] = 3\nstate['batch_verification'] = {\n    'strategy': strategy,\n    'batch_count': batch_count,\n    'total_tokens': total_tokens,\n    'expected_min_batches': expected_min_batches,\n    'batch_split_occurred': batch_count >= expected_min_batches,\n    'checks': checks,\n    'all_passed': all_passed\n}\n\nif all_passed:\n    state['TEST_RESULT'] = f'✅ COST_OPTIMIZED SUCCESS: Processed {total_tokens} tokens across {batch_count} batches (limit: 10000)'\n    state['VALIDATION_STATUS'] = 'PASSED'\n    print('✅ Cost optimization validation passed')\nelse:\n    failed_checks = []\n    if strategy != 'COST_OPTIMIZED': failed_checks.append(f'strategy={strategy}')\n    if batch_count < expected_min_batches: failed_checks.append(f'batch_count={batch_count}<{expected_min_batches}')\n    if total_tokens <= 20000: failed_checks.append(f'total_tokens={total_tokens}<=20000')\n    \n    state['TEST_RESULT'] = f'❌ COST_OPTIMIZED FAILED: {failed_checks}'\n    state['VALIDATION_STATUS'] = 'FAILED'\n    print(f'❌ Cost optimization validation failed: {failed_checks}')"
      }
    },
    {
      "id": "aggregator",
      "type": "operator",
      "label": "토큰 사용량 집계",
      "config": {
        "language": "python",
        "code": "# 병렬 브랜치들의 토큰 사용량 합산\nimport json\n\ndef extract_token_usage(data):\n    \"\"\"\n    Extract token usage from various data structures\n    \"\"\"\n    if not isinstance(data, dict):\n        return {'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0}\n    \n    # Try 'usage' key first (legacy)\n    usage = data.get('usage', {})\n    if usage and isinstance(usage, dict):\n        return {\n            'input_tokens': usage.get('input_tokens', 0),\n            'output_tokens': usage.get('output_tokens', 0),\n            'total_tokens': usage.get('total_tokens', 0)\n        }\n    \n    # Try 'token_usage' key\n    token_usage = data.get('token_usage', {})\n    if token_usage and isinstance(token_usage, dict):\n        return {\n            'input_tokens': token_usage.get('input_tokens', 0),\n            'output_tokens': token_usage.get('output_tokens', 0),\n            'total_tokens': token_usage.get('total_tokens', 0)\n        }\n    \n    # Try direct keys\n    total_input = data.get('total_input_tokens', 0)\n    total_output = data.get('total_output_tokens', 0)\n    total_tokens = data.get('total_tokens', 0)\n    \n    if total_input > 0 or total_output > 0 or total_tokens > 0:\n        return {\n            'input_tokens': total_input,\n            'output_tokens': total_output,\n            'total_tokens': total_tokens\n        }\n    \n    # Default\n    return {'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0}\n\n# parallel_group_runner에서 이미 계산된 토큰 값을 사용\nparallel_result = state.get('cost_aware_parallel', {})\n\n# 병렬 그룹이 직접 계산한 토큰 값을 사용\naggregated_input_tokens = parallel_result.get('total_input_tokens', 0)\naggregated_output_tokens = parallel_result.get('total_output_tokens', 0)\naggregated_total_tokens = parallel_result.get('total_tokens', 0)\nbranch_token_details = parallel_result.get('branch_token_details', [])\n\nprint(f'[DEBUG] Aggregator - parallel_result keys: {list(parallel_result.keys())}')\nprint(f'[DEBUG] Aggregator - total_tokens from parallel: {aggregated_total_tokens}')\n\n# 최종 결과에 기록\nstate['total_tokens'] = aggregated_total_tokens\nstate['total_input_tokens'] = aggregated_input_tokens\nstate['total_output_tokens'] = aggregated_output_tokens\nstate['branch_token_details'] = branch_token_details\n\n# 스케줄링 메타데이터에서 배치 정보 추출\nscheduling_metadata = state.get('scheduling_metadata', {})\nbatch_count = scheduling_metadata.get('batch_count', 1)\nstate['batch_count_actual'] = batch_count\n\nprint(f'Aggregated tokens from parallel_group: {aggregated_total_tokens} total ({aggregated_input_tokens} input + {aggregated_output_tokens} output) across {len(branch_token_details)} branches')\nprint(f'Batch count: {batch_count}')\n\nstate['aggregation_complete'] = True"
      }
    },
    {
      "id": "verify",
      "type": "operator",
      "label": "비용 최적화 검증",
      "config": {
        "language": "python",
        "code": "import json\n\nprint('[COST_OPTIMIZED VERIFICATION] Checking batch split results')\n\n# ① scheduling_metadata 추출\nmetadata = state.get('scheduling_metadata', {})\nbatch_count = metadata.get('batch_count', 0)\nstrategy = metadata.get('strategy', '')\ntotal_tokens = state.get('total_tokens', 0)  # Aggregator에서 계산된 값 사용\nbatch_splits = metadata.get('batch_splits', [])\n\nprint(f'Metadata: {json.dumps(metadata, indent=2)}')\nprint(f'Aggregated total tokens: {total_tokens}')\n\n# ② 예상 검증: 토큰 제한(10000) vs 실제 부하(25,000)\n# 25,000 / 10,000 = 2.5 -> 최소 3개 배치 필요\nexpected_min_batches = 3  # 여유 있게 3개 설정\n\nchecks = [\n    strategy == 'COST_OPTIMIZED',\n    batch_count >= expected_min_batches,\n    total_tokens > 20000,  # 최소 20k 토큰 확인\n    isinstance(batch_splits, list),\n    len(batch_splits) >= 1\n]\n\nall_passed = all(checks)\n\nprint(f'Strategy: {strategy} (expected: COST_OPTIMIZED)')\nprint(f'Batch Count: {batch_count} (expected: >={expected_min_batches})')\nprint(f'Total Tokens: {total_tokens} (expected: >20000)')\nprint(f'Batch Splits: {len(batch_splits)} batches')\nprint(f'All checks passed: {all_passed}')\n\nstate['cost_test_complete'] = True\nstate['branch_count'] = 3\nstate['batch_verification'] = {\n    'strategy': strategy,\n    'batch_count': batch_count,\n    'total_tokens': total_tokens,\n    'expected_min_batches': expected_min_batches,\n    'batch_split_occurred': batch_count >= expected_min_batches,\n    'checks': checks,\n    'all_passed': all_passed\n}\n\nif all_passed:\n    state['TEST_RESULT'] = f'✅ COST_OPTIMIZED SUCCESS: Processed {total_tokens} tokens across {batch_count} batches (limit: 10000)'\n    state['VALIDATION_STATUS'] = 'PASSED'\n    print('✅ Cost optimization validation passed')\nelse:\n    failed_checks = []\n    if strategy != 'COST_OPTIMIZED': failed_checks.append(f'strategy={strategy}')\n    if batch_count < expected_min_batches: failed_checks.append(f'batch_count={batch_count}<{expected_min_batches}')\n    if total_tokens <= 20000: failed_checks.append(f'total_tokens={total_tokens}<=20000')\n    \n    state['TEST_RESULT'] = f'❌ COST_OPTIMIZED FAILED: {failed_checks}'\n    state['VALIDATION_STATUS'] = 'FAILED'\n    print(f'❌ Cost optimization validation failed: {failed_checks}')"
      }
    }
  ],
  "edges": [
    {
      "source": "setup",
      "target": "cost_aware_parallel"
    },
    {
      "source": "cost_aware_parallel",
      "target": "aggregator"
    },
    {
      "source": "aggregator",
      "target": "verify"
    }
  ],
  "start_node": "setup",
  "initial_state": {
    "distributed_mode": true
  },
  "metadata": {
    "test_features": [
      "cost_optimized_strategy",
      "token_based_batch_splitting",
      "token_stress_test",
      "scheduling_metadata_verification"
    ],
    "expected_behavior": "Kernel should split 25,000 tokens across multiple batches due to 10,000 token limit",
    "failure_mode": "No batch splitting occurs, all branches run concurrently exceeding token budget"
  }
}