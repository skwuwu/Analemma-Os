"""
í•µì‹¬ ê¸°ëŠ¥ í†µí•© í…ŒìŠ¤íŠ¸ (Edge Cases ê°•í™”)

í…ŒìŠ¤íŠ¸ ëŒ€ìƒ:
- Plan Briefing: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì „ ë¯¸ë¦¬ë³´ê¸°
- Task Manager: ë¹„ì¦ˆë‹ˆìŠ¤ ì¹œí™”ì  Task ì •ë³´ ë³€í™˜
- Instruction Distiller: ì§€ì¹¨ ì¶©ëŒ ê°ì§€ ë° í•´ê²°

ì›ì¹™:
- AWS ì„œë¹„ìŠ¤ë§Œ mock (DynamoDB, S3 ë“±)
- í”„ë¡œë•ì…˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì½”ë“œ ì§ì ‘ ì‚¬ìš©
- ğŸš¨ Edge Cases: ìˆœí™˜ ì°¸ì¡°, ê³ ë¦½ ë…¸ë“œ, ë¯¸ë¶„ë¥˜ ì—ëŸ¬, ê²½ê³„ê°’, DynamoDB ì™•ë³µ ë“±

í…ŒìŠ¤íŠ¸ ì² í•™: "ì„¤ê³„ë„ëŒ€ë¡œ ë§Œë“  ê¸°ê³„ì— ëª¨ë˜ë¥¼ ë¿Œë ¤ë„ ì˜ ëŒì•„ê°€ë‚˜?"
"""
import pytest
import json
import sys
import os
from unittest.mock import MagicMock, AsyncMock
from moto import mock_aws
import boto3
from datetime import datetime, timezone
from decimal import Decimal
from pydantic import ValidationError
from collections import defaultdict, deque

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ.setdefault("AWS_DEFAULT_REGION", "us-east-1")
os.environ.setdefault("MOCK_MODE", "true")
os.environ.setdefault("CORRECTIONS_TABLE", "test-corrections")
os.environ.setdefault("INSTRUCTIONS_TABLE", "test-instructions")


# ============================================================================
# ğŸ§ª Plan Briefing í…ŒìŠ¤íŠ¸ (Edge Cases í¬í•¨)
# ============================================================================
class TestPlanBriefingCore:
    """Plan Briefing í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    def test_plan_step_model_validation(self):
        """Plan Step ëª¨ë¸ì´ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ëŠ”ì§€ ê²€ì¦"""
        from backend.models.plan_briefing import PlanStep, RiskLevel
        
        step = PlanStep(
            step_number=1,
            node_id="node-1",
            node_name="ì´ë©”ì¼ ì‘ì„±",
            node_type="llm",
            action_description="GPT-4ë¡œ ì´ë©”ì¼ ì´ˆì•ˆ ìƒì„±",
            estimated_duration_seconds=5,
            risk_level=RiskLevel.LOW
        )
        
        assert step.step_number == 1
        assert step.node_id == "node-1"
        assert step.risk_level == RiskLevel.LOW
        assert step.has_external_side_effect == False
    
    def test_plan_step_with_external_side_effect(self):
        """ì™¸ë¶€ ì˜í–¥ì´ ìˆëŠ” ë‹¨ê³„ê°€ ì˜¬ë°”ë¥´ê²Œ í‘œì‹œë˜ëŠ”ì§€ ê²€ì¦"""
        from backend.models.plan_briefing import PlanStep, RiskLevel
        
        step = PlanStep(
            step_number=2,
            node_id="node-2",
            node_name="ì´ë©”ì¼ ë°œì†¡",
            node_type="email",
            action_description="ì‘ì„±ëœ ì´ë©”ì¼ì„ ê³ ê°ì—ê²Œ ë°œì†¡",
            estimated_duration_seconds=3,
            risk_level=RiskLevel.HIGH,
            risk_description="ì´ë©”ì¼ ë°œì†¡ í›„ ë˜ëŒë¦´ ìˆ˜ ì—†ìŒ",
            has_external_side_effect=True,
            external_systems=["SMTP", "SendGrid"]
        )
        
        assert step.risk_level == RiskLevel.HIGH
        assert step.has_external_side_effect == True
        assert "SendGrid" in step.external_systems
    
    def test_draft_result_model(self):
        """Draft Result ëª¨ë¸ ê²€ì¦"""
        from backend.models.plan_briefing import DraftResult
        
        draft = DraftResult(
            result_type="email",
            title="ê³ ê° ë¬¸ì˜ ë‹µë³€ ì´ë©”ì¼",
            content_preview="ì•ˆë…•í•˜ì„¸ìš”, ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ë‹µë³€ë“œë¦½ë‹ˆë‹¤..."
        )
        
        assert draft.result_type == "email"
        assert draft.title == "ê³ ê° ë¬¸ì˜ ë‹µë³€ ì´ë©”ì¼"
        assert draft.result_id is not None  # ìë™ ìƒì„±ë¨
        assert "ì•ˆë…•í•˜ì„¸ìš”" in draft.content_preview
    
    def test_plan_briefing_service_default_durations(self):
        """Plan Briefing ì„œë¹„ìŠ¤ì˜ ê¸°ë³¸ ì†Œìš” ì‹œê°„ ì„¤ì • ê²€ì¦"""
        from backend.services.plan_briefing_service import PlanBriefingService
        
        service = PlanBriefingService()
        
        # ë…¸ë“œ íƒ€ì…ë³„ ê¸°ë³¸ ì†Œìš” ì‹œê°„ í™•ì¸
        assert service.DEFAULT_DURATIONS["llm"] == 5
        assert service.DEFAULT_DURATIONS["hitp"] == 30  # HITLì€ ëŒ€ê¸° ì‹œê°„ì´ ê¹€
        assert service.DEFAULT_DURATIONS["api_call"] == 3
    
    def test_plan_briefing_service_side_effect_types(self):
        """ì™¸ë¶€ ì˜í–¥ì´ ìˆëŠ” ë…¸ë“œ íƒ€ì… ì‹ë³„ ê²€ì¦"""
        from backend.services.plan_briefing_service import PlanBriefingService
        
        service = PlanBriefingService()
        
        # ì™¸ë¶€ ì˜í–¥ì´ ìˆëŠ” íƒ€ì…ë“¤
        assert "email" in service.SIDE_EFFECT_TYPES
        assert "payment" in service.SIDE_EFFECT_TYPES
        assert "webhook" in service.SIDE_EFFECT_TYPES
    
    # ========================================================================
    # ğŸš¨ Edge Case: ì˜ëª»ëœ ì…ë ¥ í…ŒìŠ¤íŠ¸ (ì˜ë„ì  ì‹¤íŒ¨)
    # ========================================================================
    def test_plan_step_invalid_risk_level_raises_error(self):
        """ì •ì˜ë˜ì§€ ì•Šì€ RiskLevel ë¬¸ìì—´ ì£¼ì… ì‹œ ValidationError"""
        from backend.models.plan_briefing import PlanStep
        
        with pytest.raises(ValidationError):
            PlanStep(
                step_number=1,
                node_id="n1",
                node_name="test",
                node_type="llm",
                action_description="test action",
                estimated_duration_seconds=5,
                risk_level="VERY_DANGEROUS"  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê°’
            )
    
    def test_plan_step_negative_step_number_raises_error(self):
        """step_number < 1 ì´ë©´ ValidationError"""
        from backend.models.plan_briefing import PlanStep, RiskLevel
        
        with pytest.raises(ValidationError):
            PlanStep(
                step_number=0,  # ge=1 ìœ„ë°˜
                node_id="n1",
                node_name="test",
                node_type="llm",
                action_description="test",
                estimated_duration_seconds=5,
                risk_level=RiskLevel.LOW
            )
    
    def test_plan_step_negative_duration_raises_error(self):
        """estimated_duration_seconds < 0 ì´ë©´ ValidationError"""
        from backend.models.plan_briefing import PlanStep, RiskLevel
        
        with pytest.raises(ValidationError):
            PlanStep(
                step_number=1,
                node_id="n1",
                node_name="test",
                node_type="llm",
                action_description="test",
                estimated_duration_seconds=-10,  # ge=0 ìœ„ë°˜
                risk_level=RiskLevel.LOW
            )
    
    # ========================================================================
    # ğŸš¨ Edge Case: ë¯¸ì •ì˜ ë…¸ë“œ íƒ€ì… (DEFAULT_DURATIONSì— ì—†ìŒ)
    # ========================================================================
    def test_undefined_node_type_uses_default_duration(self):
        """DEFAULT_DURATIONSì— ì—†ëŠ” ìƒˆ ë…¸ë“œ íƒ€ì… â†’ 'default' í´ë°±"""
        from backend.services.plan_briefing_service import PlanBriefingService
        
        service = PlanBriefingService()
        
        # "quantum_processor" ê°™ì€ ë¯¸ë˜í˜• ë…¸ë“œ íƒ€ì…
        unknown_type = "quantum_processor_v99"
        
        # ì„œë¹„ìŠ¤ëŠ” .get()ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•´ì•¼ í•¨
        duration = service.DEFAULT_DURATIONS.get(unknown_type, service.DEFAULT_DURATIONS["default"])
        
        assert duration == service.DEFAULT_DURATIONS["default"]
        assert duration == 2  # default = 2ì´ˆ


# ============================================================================
# ğŸ§ª Task Manager í…ŒìŠ¤íŠ¸ (Edge Cases í¬í•¨)
# ============================================================================
class TestTaskManagerCore:
    """Task Manager í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (Table-Driven)"""
    
    @pytest.mark.parametrize("technical_status,expected_business_status", [
        ("RUNNING", "IN_PROGRESS"),
        ("PAUSED_FOR_HITP", "PENDING_APPROVAL"),
        ("COMPLETED", "COMPLETED"),
        ("FAILED", "FAILED"),
        # Edge cases: ë‹¤ì–‘í•œ ì¼€ì´ì‹±
        ("running", "IN_PROGRESS"),
        ("Running", "IN_PROGRESS"),
        ("STARTED", "IN_PROGRESS"),
        ("SUCCEEDED", "COMPLETED"),
        ("TIMED_OUT", "FAILED"),
        ("ABORTED", "CANCELLED"),
    ])
    def test_task_status_conversion(self, technical_status, expected_business_status):
        """ê¸°ìˆ ì  ìƒíƒœë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¹œí™”ì  ìƒíƒœë¡œ ë³€í™˜ (Table-Driven)"""
        from src.models.task_context import convert_technical_status, TaskStatus
        
        result = convert_technical_status(technical_status)
        expected = TaskStatus[expected_business_status]
        assert result == expected
    
    @pytest.mark.parametrize("error_input,expected_keyword", [
        ("timeout error occurred", "ì‹œê°„"),
        ("403 forbidden", "ê¶Œí•œ"),
        ("connection refused", "ì—°ê²°"),
        ("401 unauthorized", "ì¸ì¦"),
        ("500 internal server error", "ë¬¸ì œ"),
        # Edge cases: í˜¼í•©ëœ ì—ëŸ¬ ë©”ì‹œì§€
        ("Request timeout after 30 seconds", "ì‹œê°„"),
        ("ERROR 503 Service Unavailable", "ì´ìš©"),
    ])
    def test_friendly_error_message_generation(self, error_input, expected_keyword):
        """ê¸°ìˆ ì  ì—ëŸ¬ë¥¼ ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ë¡œ ë³€í™˜ (Table-Driven)"""
        from src.models.task_context import get_friendly_error_message
        
        error_msg, suggestion = get_friendly_error_message(error_input)
        assert expected_keyword in error_msg or expected_keyword in suggestion
    
    def test_task_context_model(self):
        """TaskContext ëª¨ë¸ ìƒì„± ë° ê²€ì¦"""
        from src.models.task_context import TaskContext, TaskStatus
        
        task = TaskContext(
            task_id="task-123",
            owner_id="user-456",
            workflow_name="ì´ë©”ì¼ ìë™í™”",
            current_step_description="ì´ë©”ì¼ ì´ˆì•ˆ ì‘ì„± ì¤‘",
            status=TaskStatus.IN_PROGRESS,
            progress_percentage=45
        )
        
        assert task.task_id == "task-123"
        assert task.status == TaskStatus.IN_PROGRESS
        assert task.progress_percentage == 45
    
    def test_artifact_preview_model(self):
        """ArtifactPreview ëª¨ë¸ ê²€ì¦"""
        from src.models.task_context import ArtifactPreview, ArtifactType
        
        preview = ArtifactPreview(
            artifact_id="artifact-001",
            artifact_type=ArtifactType.TEXT,  # TEXT ì‚¬ìš© (EMAIL ì—†ìŒ)
            title="ê³ ê° ì‘ëŒ€ ì´ë©”ì¼",
            preview_content="ì•ˆë…•í•˜ì„¸ìš”, ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´..."
        )
        
        assert preview.artifact_type == ArtifactType.TEXT
        assert "ì•ˆë…•í•˜ì„¸ìš”" in preview.preview_content
    
    # ========================================================================
    # ğŸš¨ Edge Case: ë¯¸ë¶„ë¥˜ ì—ëŸ¬ â†’ í´ë°± ë©”ì‹œì§€
    # ========================================================================
    @pytest.mark.parametrize("garbage_error", [
        "kernel panic - not syncing: VFS: Unable to mount root fs",
        "Segmentation fault (core dumped)",
        "xyzzy_unknown_error_12345",
        "å®Œå…¨ã«ç†è§£ã§ããªã„ã‚¨ãƒ©ãƒ¼",  # ì¼ë³¸ì–´ ì—ëŸ¬
        "",  # ë¹ˆ ë¬¸ìì—´
        "   ",  # ê³µë°±ë§Œ
        None,  # Noneì€ strì´ ì•„ë‹ˆë¯€ë¡œ ë³„ë„ ì²˜ë¦¬ í•„ìš”
    ])
    def test_unknown_error_returns_fallback(self, garbage_error):
        """ë¯¸ë¶„ë¥˜ ì—ëŸ¬ëŠ” í´ë°± ë©”ì‹œì§€ ë°˜í™˜ (í¬ë˜ì‹œ ì—†ìŒ)"""
        from src.models.task_context import get_friendly_error_message
        
        if garbage_error is None:
            # None ì…ë ¥ì€ í•¨ìˆ˜ì—ì„œ ì²˜ë¦¬í•´ì•¼ í•¨
            garbage_error = ""
        
        error_msg, suggestion = get_friendly_error_message(garbage_error)
        
        # í¬ë˜ì‹œ ì—†ì´ ë©”ì‹œì§€ ë°˜í™˜
        assert error_msg is not None
        assert suggestion is not None
        assert len(error_msg) > 0
        assert len(suggestion) > 0
        # í´ë°±: "ì‘ì—… ì¤‘ ë¬¸ì œê°€ ë°œìƒ"
        assert "ë¬¸ì œ" in error_msg or "ë°œìƒ" in error_msg
    
    # ========================================================================
    # ğŸš¨ Edge Case: ì§„í–‰ë¥  ê²½ê³„ê°’ (Pydantic Validation)
    # ========================================================================
    @pytest.mark.parametrize("invalid_progress", [
        -1, -10, -100,   # ìŒìˆ˜
        101, 150, 999,   # 100 ì´ˆê³¼
    ])
    def test_progress_percentage_boundary_validation(self, invalid_progress):
        """progress_percentage 0~100 ë²”ìœ„ ë²—ì–´ë‚˜ë©´ ValidationError"""
        from src.models.task_context import TaskContext, TaskStatus
        
        with pytest.raises(ValidationError):
            TaskContext(
                task_id="task-boundary",
                progress_percentage=invalid_progress  # ge=0, le=100 ìœ„ë°˜
            )
    
    @pytest.mark.parametrize("valid_progress", [0, 1, 50, 99, 100])
    def test_progress_percentage_valid_range(self, valid_progress):
        """0~100 ë²”ìœ„ ë‚´ progress_percentageëŠ” ì •ìƒ ìƒì„±"""
        from src.models.task_context import TaskContext, TaskStatus
        
        task = TaskContext(
            task_id="task-valid",
            progress_percentage=valid_progress
        )
        assert task.progress_percentage == valid_progress
    
    # ========================================================================
    # ğŸš¨ Edge Case: ë¯¸ì •ì˜ ê¸°ìˆ  ìƒíƒœ â†’ ê¸°ë³¸ê°’ í´ë°±
    # ========================================================================
    @pytest.mark.parametrize("unknown_status", [
        "QUANTUM_SUPERPOSITION",
        "STATUS_404_NOT_FOUND",
        "",
        "null",
    ])
    def test_unknown_technical_status_falls_back(self, unknown_status):
        """ë¯¸ì •ì˜ ê¸°ìˆ  ìƒíƒœ â†’ IN_PROGRESSë¡œ í´ë°±"""
        from src.models.task_context import convert_technical_status, TaskStatus
        
        result = convert_technical_status(unknown_status)
        
        # ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœëŠ” IN_PROGRESSë¡œ í´ë°±
        assert result == TaskStatus.IN_PROGRESS


# ============================================================================
# ğŸ§ª Instruction Distiller (ì§€ì¹¨ ì¶©ëŒ ê°ì§€) í…ŒìŠ¤íŠ¸ - Edge Cases í¬í•¨
# ============================================================================
class TestInstructionDistillerCore:
    """ì§€ì¹¨ ì¦ë¥˜ê¸° í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    def test_correction_type_enum(self):
        """ìˆ˜ì • íƒ€ì… ì—´ê±°í˜• ê²€ì¦"""
        from src.models.correction_log import CorrectionType
        
        assert CorrectionType.TONE.value == "tone"
        assert CorrectionType.FORMAT.value == "format"
        assert CorrectionType.CONTENT.value == "content"
        assert CorrectionType.STYLE.value == "style"
    
    def test_task_category_enum(self):
        """íƒœìŠ¤í¬ ì¹´í…Œê³ ë¦¬ ì—´ê±°í˜• ê²€ì¦"""
        from src.models.correction_log import TaskCategory
        
        assert TaskCategory.EMAIL.value == "email"
        assert TaskCategory.SQL.value == "sql"
        assert TaskCategory.DOCUMENT.value == "document"
    
    def test_correction_log_model_creation(self):
        """CorrectionLog ëª¨ë¸ ìƒì„± ê²€ì¦"""
        from src.models.correction_log import CorrectionLog, TaskCategory
        
        log = CorrectionLog(
            pk="user#user123",
            user_id="user123",
            workflow_id="wf-001",
            node_id="node-001",
            task_category=TaskCategory.EMAIL,
            original_input="ê³ ê° ë¬¸ì˜ ë‚´ìš©",
            agent_output="ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜.",
            user_correction="ì•ˆë…•í•˜ì„¸ìš”, ê³ ê°ë‹˜! ê°ì‚¬í•©ë‹ˆë‹¤.",
            edit_distance=12,
            correction_time_seconds=30,
            # í•„ìˆ˜ í•„ë“œ ì¶”ê°€
            node_type="llm_operator",
            workflow_domain="sales",
            context_scope="global"
        )
        
        assert log.user_id == "user123"
        assert log.task_category == TaskCategory.EMAIL
        assert log.edit_distance == 12
        assert log.node_type == "llm_operator"
    
    def test_distilled_instruction_model(self):
        """DistilledInstruction ëª¨ë¸ ê²€ì¦"""
        from src.models.correction_log import DistilledInstruction, CorrectionType
        
        instruction = DistilledInstruction(
            pk="user#user123",
            user_id="user123",
            category=CorrectionType.TONE,
            context_scope="email_response",
            instruction="í•­ìƒ ê°ì‚¬ ì¸ì‚¬ë¡œ ì‹œì‘í•˜ê³  ëë‚´ê¸°",
            confidence=0.85,
            source_correction_ids=["corr-001", "corr-002"],
            pattern_description="3íšŒ ì´ìƒ ë™ì¼ íŒ¨í„´ ê°ì§€ë¨",
            metadata_signature={"tone": "friendly", "formality": "formal"}
        )
        
        assert instruction.confidence == 0.85
        assert len(instruction.source_correction_ids) == 2
        assert instruction.metadata_signature["tone"] == "friendly"
    
    def test_conflict_resolver_detect_conflicts(self):
        """ì¶©ëŒ ê°ì§€ ë¡œì§ ê²€ì¦"""
        from src.models.correction_log import ConflictResolver, DistilledInstruction, CorrectionType
        
        resolver = ConflictResolver()
        
        # ê¸°ì¡´ ì§€ì¹¨
        existing = [
            DistilledInstruction(
                pk="user#user123",
                sk="instruction#001",
                user_id="user123",
                category=CorrectionType.TONE,
                context_scope="email_response",
                instruction="ê²©ì‹ì²´ ì‚¬ìš©",
                confidence=0.8,
                source_correction_ids=["c1"],
                pattern_description="formal tone",
                metadata_signature={"tone": "formal", "formality": "formal"}
            )
        ]
        
        # ì¶©ëŒí•˜ëŠ” ìƒˆ ë©”íƒ€ë°ì´í„° (casual vs formal)
        new_signature = {"tone": "casual", "formality": "informal"}
        
        # ì‹¤ì œ API ì‹œê·¸ë‹ˆì²˜ì— ë§ê²Œ í˜¸ì¶œ
        conflicts = resolver.detect_conflicts(
            existing_instructions=existing,
            new_signature=new_signature,
            category=CorrectionType.TONE,
            context_scope="email_response"
        )
        
        # toneê³¼ formality ëª¨ë‘ ì¶©ëŒí•´ì•¼ í•¨
        assert len(conflicts) >= 1
    
    # ========================================================================
    # ğŸš¨ Edge Case: ë¶€ë¶„ì  ì‹œê·¸ë‹ˆì²˜ ì¶©ëŒ
    # ========================================================================
    def test_partial_signature_conflict_tone_only(self):
        """toneë§Œ ë‹¤ë¥´ê³  formalityëŠ” ê°™ìŒ â†’ ë¶€ë¶„ ì¶©ëŒ"""
        from src.models.correction_log import DistilledInstruction, CorrectionType
        
        existing_sig = {"tone": "formal", "formality": "formal", "length": "short"}
        new_sig = {"tone": "casual", "formality": "formal"}  # toneë§Œ ì¶©ëŒ
        
        instruction = DistilledInstruction(
            pk="user#test",
            user_id="test",
            category=CorrectionType.TONE,
            context_scope="email",
            instruction="test",
            confidence=0.9,
            source_correction_ids=["c1"],
            pattern_description="test",
            metadata_signature=existing_sig
        )
        
        # ì¶©ëŒ ê°ì§€
        assert instruction.has_conflicting_signature(new_sig) == True
        
        # ì¶©ëŒ ìƒì„¸: toneë§Œ ë‹¤ë¦„
        details = instruction.get_conflict_details(new_sig)
        assert "tone" in details
        assert details["tone"]["existing"] == "formal"
        assert details["tone"]["new"] == "casual"
        assert "formality" not in details  # formalityëŠ” ê°™ìŒ
    
    def test_partial_signature_key_missing_no_conflict(self):
        """í•œìª½ì— í‚¤ê°€ ì—†ìœ¼ë©´ ì¶©ëŒ ì•„ë‹˜"""
        from src.models.correction_log import DistilledInstruction, CorrectionType
        
        existing_sig = {"tone": "formal"}  # formality ì—†ìŒ
        new_sig = {"formality": "informal"}  # tone ì—†ìŒ
        
        instruction = DistilledInstruction(
            pk="user#test",
            user_id="test",
            category=CorrectionType.TONE,
            context_scope="email",
            instruction="test",
            confidence=0.9,
            source_correction_ids=["c1"],
            pattern_description="test",
            metadata_signature=existing_sig
        )
        
        # ê³µí†µ í‚¤ê°€ ì—†ìœ¼ë©´ ì¶©ëŒ ì—†ìŒ
        assert instruction.has_conflicting_signature(new_sig) == False
    
    # ========================================================================
    # ğŸš¨ Edge Case: ëŒ€ëŸ‰ ì§€ì¹¨ ì²˜ë¦¬ (100ê°œ ì´ìƒ)
    # ========================================================================
    def test_conflict_detection_with_100_instructions(self):
        """100ê°œ ì´ìƒì˜ ê¸°ì¡´ ì§€ì¹¨ì—ì„œ ì¶©ëŒ ê°ì§€ ì„±ëŠ¥/ì •í™•ë„"""
        from src.models.correction_log import ConflictResolver, DistilledInstruction, CorrectionType
        import time
        
        resolver = ConflictResolver()
        
        # 100ê°œì˜ ê¸°ì¡´ ì§€ì¹¨ ìƒì„± (ë‹¤ì–‘í•œ ë©”íƒ€ë°ì´í„°)
        existing = []
        for i in range(100):
            tone = "formal" if i % 2 == 0 else "casual"
            formality = "formal" if i % 3 == 0 else "informal"
            
            instruction = DistilledInstruction(
                pk=f"user#user{i}",
                sk=f"instruction#{i:03d}",
                user_id=f"user{i}",
                category=CorrectionType.TONE,
                context_scope="email_response",
                instruction=f"ì§€ì¹¨ {i}",
                confidence=0.8,
                source_correction_ids=[f"c{i}"],
                pattern_description=f"pattern {i}",
                metadata_signature={"tone": tone, "formality": formality}
            )
            existing.append(instruction)
        
        # ì¶©ëŒí•˜ëŠ” ìƒˆ ì‹œê·¸ë‹ˆì²˜ (casual + formal)
        new_signature = {"tone": "casual", "formality": "formal"}
        
        start_time = time.time()
        conflicts = resolver.detect_conflicts(
            existing_instructions=existing,
            new_signature=new_signature,
            category=CorrectionType.TONE,
            context_scope="email_response"
        )
        elapsed = time.time() - start_time
        
        # ì„±ëŠ¥: 100ê°œ ì²˜ë¦¬ëŠ” 1ì´ˆ ì´ë‚´
        assert elapsed < 1.0, f"100ê°œ ì§€ì¹¨ ì²˜ë¦¬ê°€ ë„ˆë¬´ ëŠë¦¼: {elapsed:.2f}s"
        
        # ì •í™•ë„: ì¼ë¶€ëŠ” ì¶©ëŒ, ì¼ë¶€ëŠ” ì•„ë‹˜
        # tone=formalì´ê³  formality=formalì¸ ê²½ìš°ë§Œ ì¶©ëŒ (i % 2 == 0 and i % 3 == 0)
        # â†’ i = 0, 6, 12, 18, ... (0~99ì—ì„œ 17ê°œ)
        assert len(conflicts) >= 1
    
    # ========================================================================
    # ğŸš¨ Edge Case: Pydantic íƒ€ì… ê°•ì œ ë³€í™˜ (DynamoDB Decimal/String)
    # ========================================================================
    def test_confidence_string_coercion(self):
        """confidenceê°€ ë¬¸ìì—´ '0.85'ë¡œ ë“¤ì–´ì™€ë„ floatë¡œ ë³€í™˜"""
        from src.models.correction_log import DistilledInstruction, CorrectionType
        
        # DynamoDBì—ì„œ Decimalì´ ë¬¸ìì—´ë¡œ ë³€í™˜ë˜ì–´ ì˜¬ ìˆ˜ ìˆìŒ
        instruction = DistilledInstruction(
            pk="user#test",
            user_id="test",
            category=CorrectionType.TONE,
            context_scope="email",
            instruction="test",
            confidence="0.85",  # ë¬¸ìì—´ë¡œ ì£¼ì…
            source_correction_ids=["c1"],
            pattern_description="test"
        )
        
        # Pydanticì´ floatë¡œ ê°•ì œ ë³€í™˜
        assert isinstance(instruction.confidence, float)
        assert instruction.confidence == 0.85
    
    def test_edit_distance_string_coercion(self):
        """edit_distanceê°€ ë¬¸ìì—´ '42'ë¡œ ë“¤ì–´ì™€ë„ intë¡œ ë³€í™˜"""
        from src.models.correction_log import CorrectionLog, TaskCategory
        
        log = CorrectionLog(
            pk="user#test",
            user_id="test",
            workflow_id="wf-1",
            node_id="n-1",
            task_category=TaskCategory.EMAIL,
            original_input="test",
            agent_output="test",
            user_correction="test",
            edit_distance="42",  # ë¬¸ìì—´ë¡œ ì£¼ì…
            correction_time_seconds="30",  # ë¬¸ìì—´ë¡œ ì£¼ì…
            node_type="llm",
            workflow_domain="sales",
            context_scope="global"
        )
        
        assert isinstance(log.edit_distance, int)
        assert log.edit_distance == 42
        assert isinstance(log.correction_time_seconds, int)
        assert log.correction_time_seconds == 30
    
    def test_confidence_decimal_coercion(self):
        """confidenceê°€ Decimal('0.85')ë¡œ ë“¤ì–´ì™€ë„ floatë¡œ ë³€í™˜"""
        from src.models.correction_log import DistilledInstruction, CorrectionType
        
        instruction = DistilledInstruction(
            pk="user#test",
            user_id="test",
            category=CorrectionType.TONE,
            context_scope="email",
            instruction="test",
            confidence=Decimal("0.85"),  # Decimalë¡œ ì£¼ì…
            source_correction_ids=["c1"],
            pattern_description="test"
        )
        
        # Pydanticì´ floatë¡œ ë³€í™˜
        assert isinstance(instruction.confidence, float)
        assert instruction.confidence == 0.85


# ============================================================================
# ğŸ§ª ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ë¶„ì„ í…ŒìŠ¤íŠ¸ (ë³µì¡í•œ êµ¬ì¡° í¬í•¨)
# ============================================================================
class TestWorkflowAnalysisPureFunctions:
    """ì›Œí¬í”Œë¡œìš° ë¶„ì„ ìˆœìˆ˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ (ë³µì¡í•œ ê·¸ë˜í”„ êµ¬ì¡° í¬í•¨)"""
    
    def _topological_sort(self, nodes, edges):
        """í† í´ë¡œì§€ ì •ë ¬ í—¬í¼ í•¨ìˆ˜"""
        in_degree = defaultdict(int)
        adj = defaultdict(list)
        
        node_ids = {n["id"] for n in nodes}
        for n in nodes:
            in_degree[n["id"]] = 0  # ì´ˆê¸°í™”
        
        for edge in edges:
            if edge["source"] in node_ids and edge["target"] in node_ids:
                adj[edge["source"]].append(edge["target"])
                in_degree[edge["target"]] += 1
        
        # BFS í† í´ë¡œì§€ ì •ë ¬
        queue = deque([n["id"] for n in nodes if in_degree[n["id"]] == 0])
        order = []
        
        while queue:
            node = queue.popleft()
            order.append(node)
            for neighbor in adj[node]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)
        
        return order, len(order) == len(nodes)
    
    def test_workflow_node_ordering_linear(self):
        """ì„ í˜• ì›Œí¬í”Œë¡œìš°: start â†’ llm â†’ email â†’ end"""
        nodes = [
            {"id": "start", "type": "trigger"},
            {"id": "llm-1", "type": "llm"},
            {"id": "email", "type": "email"},
            {"id": "end", "type": "complete"}
        ]
        edges = [
            {"source": "start", "target": "llm-1"},
            {"source": "llm-1", "target": "email"},
            {"source": "email", "target": "end"}
        ]
        
        order, is_valid = self._topological_sort(nodes, edges)
        
        assert is_valid
        assert order == ["start", "llm-1", "email", "end"]
    
    # ========================================================================
    # ğŸš¨ Edge Case: ìˆœí™˜ ì°¸ì¡°(Cycle) ê°ì§€
    # ========================================================================
    def test_cycle_detection_simple(self):
        """ìˆœí™˜ ì°¸ì¡°ê°€ ìˆìœ¼ë©´ í† í´ë¡œì§€ ì •ë ¬ ì‹¤íŒ¨"""
        nodes = [
            {"id": "A", "type": "llm"},
            {"id": "B", "type": "llm"},
            {"id": "C", "type": "llm"},
        ]
        # A â†’ B â†’ C â†’ A (ìˆœí™˜)
        edges = [
            {"source": "A", "target": "B"},
            {"source": "B", "target": "C"},
            {"source": "C", "target": "A"},  # ìˆœí™˜!
        ]
        
        order, is_valid = self._topological_sort(nodes, edges)
        
        # ìˆœí™˜ì´ ìˆìœ¼ë©´ ëª¨ë“  ë…¸ë“œë¥¼ ì •ë ¬í•  ìˆ˜ ì—†ìŒ
        assert not is_valid
        assert len(order) < len(nodes)
    
    def test_cycle_detection_self_loop(self):
        """ìê¸° ìì‹ ì„ ê°€ë¦¬í‚¤ëŠ” Self-loop"""
        nodes = [
            {"id": "A", "type": "llm"},
            {"id": "B", "type": "llm"},
        ]
        edges = [
            {"source": "A", "target": "B"},
            {"source": "B", "target": "B"},  # Self-loop!
        ]
        
        order, is_valid = self._topological_sort(nodes, edges)
        
        # Bì˜ in_degreeê°€ ì ˆëŒ€ 0ì´ ë˜ì§€ ì•ŠìŒ
        assert not is_valid
    
    # ========================================================================
    # ğŸš¨ Edge Case: ê³ ë¦½ëœ ë…¸ë“œ(Isolated Node)
    # ========================================================================
    def test_isolated_node_handling(self):
        """ì‹œì‘ì ê³¼ ì—°ê²°ë˜ì§€ ì•Šì€ ê³ ë¦½ ë…¸ë“œ"""
        nodes = [
            {"id": "start", "type": "trigger"},
            {"id": "llm-1", "type": "llm"},
            {"id": "end", "type": "complete"},
            {"id": "isolated", "type": "llm"},  # ì•„ë¬´ê²ƒë„ ì—°ê²° ì•ˆ ë¨
        ]
        edges = [
            {"source": "start", "target": "llm-1"},
            {"source": "llm-1", "target": "end"},
            # "isolated" ë…¸ë“œëŠ” ì—£ì§€ ì—†ìŒ
        ]
        
        order, is_valid = self._topological_sort(nodes, edges)
        
        # ê³ ë¦½ ë…¸ë“œë„ in_degree=0ì´ë¯€ë¡œ ì •ë ¬ì— í¬í•¨ë¨
        assert is_valid
        assert "isolated" in order
        # ê³ ë¦½ ë…¸ë“œëŠ” ì‹œì‘ ì§€ì ë“¤ê³¼ í•¨ê»˜ ì²˜ìŒì— ë‚˜ì˜¬ ìˆ˜ ìˆìŒ
    
    def test_multiple_roots_handling(self):
        """ì—¬ëŸ¬ ì‹œì‘ì ì´ ìˆëŠ” ë³‘ë ¬ ì›Œí¬í”Œë¡œìš°"""
        nodes = [
            {"id": "root1", "type": "trigger"},
            {"id": "root2", "type": "trigger"},
            {"id": "merge", "type": "aggregator"},
            {"id": "end", "type": "complete"},
        ]
        edges = [
            {"source": "root1", "target": "merge"},
            {"source": "root2", "target": "merge"},
            {"source": "merge", "target": "end"},
        ]
        
        order, is_valid = self._topological_sort(nodes, edges)
        
        assert is_valid
        # root1, root2ê°€ ë¨¼ì € ë‚˜ì˜¤ê³ , merge, endê°€ ë’¤ì—
        assert order.index("merge") > order.index("root1")
        assert order.index("merge") > order.index("root2")
        assert order.index("end") > order.index("merge")
    
    # ========================================================================
    # ğŸš¨ Edge Case: ë³µì¡í•œ ë‹¤ì´ì•„ëª¬ë“œ êµ¬ì¡°
    # ========================================================================
    def test_diamond_dependency(self):
        """ë‹¤ì´ì•„ëª¬ë“œ ì˜ì¡´ì„±: A â†’ B, A â†’ C, B â†’ D, C â†’ D"""
        nodes = [
            {"id": "A", "type": "trigger"},
            {"id": "B", "type": "llm"},
            {"id": "C", "type": "llm"},
            {"id": "D", "type": "aggregator"},
        ]
        edges = [
            {"source": "A", "target": "B"},
            {"source": "A", "target": "C"},
            {"source": "B", "target": "D"},
            {"source": "C", "target": "D"},
        ]
        
        order, is_valid = self._topological_sort(nodes, edges)
        
        assert is_valid
        assert order[0] == "A"
        assert order[-1] == "D"
        # B, CëŠ” A ë‹¤ìŒ, D ì „ì— (ìˆœì„œ ë¶ˆí™•ì •)
        assert order.index("B") > order.index("A")
        assert order.index("C") > order.index("A")
    
    def test_risk_level_calculation(self):
        """ë…¸ë“œ íƒ€ì…ì— ë”°ë¥¸ ìœ„í—˜ ìˆ˜ì¤€ ê³„ì‚°"""
        from backend.models.plan_briefing import RiskLevel
        
        def calculate_risk_level(node_type: str, has_side_effect: bool) -> RiskLevel:
            """ë…¸ë“œ íƒ€ì…ê³¼ ì™¸ë¶€ ì˜í–¥ ì—¬ë¶€ë¡œ ìœ„í—˜ ìˆ˜ì¤€ ê³„ì‚°"""
            high_risk_types = {"email", "payment", "webhook", "sms"}
            medium_risk_types = {"api_call", "database_write"}
            
            if node_type in high_risk_types or (has_side_effect and node_type in medium_risk_types):
                return RiskLevel.HIGH
            elif node_type in medium_risk_types:
                return RiskLevel.MEDIUM
            else:
                return RiskLevel.LOW
        
        assert calculate_risk_level("llm", False) == RiskLevel.LOW
        assert calculate_risk_level("api_call", False) == RiskLevel.MEDIUM
        assert calculate_risk_level("email", True) == RiskLevel.HIGH
        assert calculate_risk_level("payment", True) == RiskLevel.HIGH
    
    # ========================================================================
    # ğŸš¨ Edge Case: ë¹ˆ ì›Œí¬í”Œë¡œìš°, ë…¸ë“œë§Œ ìˆëŠ” ê²½ìš°
    # ========================================================================
    def test_empty_workflow(self):
        """ë…¸ë“œë„ ì—£ì§€ë„ ì—†ëŠ” ë¹ˆ ì›Œí¬í”Œë¡œìš°"""
        nodes = []
        edges = []
        
        order, is_valid = self._topological_sort(nodes, edges)
        
        assert is_valid
        assert order == []
    
    def test_nodes_only_no_edges(self):
        """ì—£ì§€ ì—†ì´ ë…¸ë“œë§Œ ìˆìŒ â†’ ëª¨ë‘ ê³ ë¦½"""
        nodes = [
            {"id": "A", "type": "llm"},
            {"id": "B", "type": "llm"},
            {"id": "C", "type": "llm"},
        ]
        edges = []
        
        order, is_valid = self._topological_sort(nodes, edges)
        
        assert is_valid
        assert len(order) == 3


# ============================================================================
# ğŸ§ª ë©”íƒ€ë°ì´í„° ì‹œê·¸ë‹ˆì²˜ ì¶©ëŒ í…ŒìŠ¤íŠ¸ (ë¶€ë¶„ ì¼ì¹˜ í¬í•¨)
# ============================================================================
class TestMetadataSignatureConflict:
    """ë©”íƒ€ë°ì´í„° ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ ì¶©ëŒ ê°ì§€ í…ŒìŠ¤íŠ¸ (Edge Cases í¬í•¨)"""
    
    def _signatures_conflict(self, s1: dict, s2: dict) -> bool:
        """ë‘ ì‹œê·¸ë‹ˆì²˜ê°€ ê°™ì€ í‚¤ì— ë‹¤ë¥¸ ê°’ì„ ê°€ì§€ë©´ ì¶©ëŒ"""
        for key in set(s1.keys()) & set(s2.keys()):
            if s1[key] != s2[key]:
                return True
        return False
    
    def test_signature_exact_match(self):
        """ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì‹œê·¸ë‹ˆì²˜ â†’ ì¶©ëŒ ì•„ë‹˜"""
        sig1 = {"tone": "formal", "length": "short"}
        sig2 = {"tone": "formal", "length": "short"}
        
        assert not self._signatures_conflict(sig1, sig2)
    
    def test_signature_conflict_detection(self):
        """ì¶©ëŒí•˜ëŠ” ì‹œê·¸ë‹ˆì²˜ ê°ì§€"""
        sig1 = {"tone": "formal", "length": "short"}
        sig2 = {"tone": "casual", "length": "short"}  # tone ì¶©ëŒ
        
        assert self._signatures_conflict(sig1, sig2)
    
    def test_signature_no_overlap(self):
        """ê²¹ì¹˜ëŠ” í‚¤ê°€ ì—†ìœ¼ë©´ ì¶©ëŒ ì—†ìŒ"""
        sig1 = {"tone": "formal"}
        sig2 = {"length": "short"}
        
        assert not self._signatures_conflict(sig1, sig2)
    
    # ========================================================================
    # ğŸš¨ Edge Case: ë‹¤ì–‘í•œ ë¶€ë¶„ ì¼ì¹˜ ì‹œë‚˜ë¦¬ì˜¤
    # ========================================================================
    def test_signature_subset_match(self):
        """í•œìª½ì´ ë‹¤ë¥¸ ìª½ì˜ ì„œë¸Œì…‹ (ì¼ì¹˜í•˜ëŠ” í‚¤ë“¤)"""
        sig1 = {"tone": "formal", "length": "short", "formality": "formal"}
        sig2 = {"tone": "formal"}  # ì„œë¸Œì…‹
        
        # ê³µí†µ í‚¤(tone)ê°€ ê°™ìœ¼ë©´ ì¶©ëŒ ì•„ë‹˜
        assert not self._signatures_conflict(sig1, sig2)
    
    def test_signature_empty(self):
        """ë¹ˆ ì‹œê·¸ë‹ˆì²˜ì™€ì˜ ë¹„êµ"""
        sig1 = {"tone": "formal"}
        sig2 = {}
        
        assert not self._signatures_conflict(sig1, sig2)
        assert not self._signatures_conflict({}, {})
    
    def test_signature_multiple_conflicts(self):
        """ì—¬ëŸ¬ í‚¤ê°€ ë™ì‹œì— ì¶©ëŒ"""
        sig1 = {"tone": "formal", "length": "short", "style": "direct"}
        sig2 = {"tone": "casual", "length": "long", "style": "diplomatic"}
        
        # ëª¨ë“  í‚¤ê°€ ë‹¤ë¦„
        assert self._signatures_conflict(sig1, sig2)
        
        # ì¶©ëŒ ê°œìˆ˜ í™•ì¸
        conflict_count = sum(
            1 for k in set(sig1.keys()) & set(sig2.keys())
            if sig1[k] != sig2[k]
        )
        assert conflict_count == 3


# ============================================================================
# ğŸ§ª DynamoDB ì™•ë³µ í…ŒìŠ¤íŠ¸ (Moto í™œìš©)
# ============================================================================
class TestDynamoDBRoundTrip:
    """DynamoDB put_item â†’ query â†’ Pydantic ë³µì› í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def dynamodb_table(self):
        """motoë¡œ ê°€ì§œ DynamoDB í…Œì´ë¸” ìƒì„±"""
        with mock_aws():
            dynamodb = boto3.resource('dynamodb', region_name='us-east-1')
            
            table = dynamodb.create_table(
                TableName='test-corrections',
                KeySchema=[
                    {'AttributeName': 'pk', 'KeyType': 'HASH'},
                    {'AttributeName': 'sk', 'KeyType': 'RANGE'}
                ],
                AttributeDefinitions=[
                    {'AttributeName': 'pk', 'AttributeType': 'S'},
                    {'AttributeName': 'sk', 'AttributeType': 'S'}
                ],
                BillingMode='PAY_PER_REQUEST'
            )
            
            # í…Œì´ë¸”ì´ í™œì„±í™”ë  ë•Œê¹Œì§€ ëŒ€ê¸°
            table.meta.client.get_waiter('table_exists').wait(TableName='test-corrections')
            
            yield table
    
    def test_correction_log_roundtrip(self, dynamodb_table):
        """CorrectionLog: ìƒì„± â†’ DynamoDB ì €ì¥ â†’ ì¡°íšŒ â†’ Pydantic ë³µì›"""
        from src.models.correction_log import CorrectionLog, TaskCategory
        
        # 1. Pydantic ëª¨ë¸ ìƒì„±
        original_log = CorrectionLog(
            pk="user#roundtrip-user",
            user_id="roundtrip-user",
            workflow_id="wf-roundtrip",
            node_id="node-roundtrip",
            task_category=TaskCategory.EMAIL,
            original_input="ì›ë³¸ ì…ë ¥ í…ŒìŠ¤íŠ¸",
            agent_output="ì—ì´ì „íŠ¸ ì¶œë ¥",
            user_correction="ì‚¬ìš©ì ìˆ˜ì •ë³¸",
            edit_distance=42,
            correction_time_seconds=120,
            node_type="llm_operator",
            workflow_domain="sales",
            context_scope="global"
        )
        
        # 2. DynamoDBì— ì €ì¥ (Pydantic â†’ dict â†’ DynamoDB)
        item = json.loads(original_log.model_dump_json())
        
        # Enum ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (DynamoDBëŠ” Enum ì§ì ‘ ì €ì¥ ë¶ˆê°€)
        if 'task_category' in item and hasattr(item['task_category'], 'value'):
            item['task_category'] = item['task_category'].value
        
        dynamodb_table.put_item(Item=item)
        
        # 3. DynamoDBì—ì„œ ì¡°íšŒ
        response = dynamodb_table.get_item(
            Key={'pk': original_log.pk, 'sk': original_log.sk}
        )
        retrieved_item = response.get('Item', {})
        
        # 4. ì¡°íšŒëœ ë°ì´í„°ë¡œ Pydantic ëª¨ë¸ ë³µì›
        restored_log = CorrectionLog(**retrieved_item)
        
        # 5. ì›ë³¸ê³¼ ë¹„êµ
        assert restored_log.user_id == original_log.user_id
        assert restored_log.workflow_id == original_log.workflow_id
        assert restored_log.task_category == original_log.task_category
        assert restored_log.edit_distance == original_log.edit_distance
        assert restored_log.original_input == original_log.original_input
    
    def test_enum_serialization_deserialization(self, dynamodb_table):
        """Enum ê°’ì˜ ì§ë ¬í™”/ì—­ì§ë ¬í™” ê²€ì¦"""
        from src.models.correction_log import TaskCategory, VectorSyncStatus
        
        # Enumì„ ë¬¸ìì—´ë¡œ ì €ì¥
        item = {
            'pk': 'test#enum',
            'sk': 'enum#001',
            'task_category': TaskCategory.SQL.value,  # "sql"
            'vector_sync_status': VectorSyncStatus.PENDING.value  # "pending"
        }
        
        dynamodb_table.put_item(Item=item)
        
        # ì¡°íšŒ
        response = dynamodb_table.get_item(Key={'pk': 'test#enum', 'sk': 'enum#001'})
        retrieved = response.get('Item', {})
        
        # ë¬¸ìì—´ â†’ Enum ë³µì›
        assert TaskCategory(retrieved['task_category']) == TaskCategory.SQL
        assert VectorSyncStatus(retrieved['vector_sync_status']) == VectorSyncStatus.PENDING
    
    def test_decimal_handling_from_dynamodb(self, dynamodb_table):
        """DynamoDB Decimal íƒ€ì… â†’ Python float/int ë³€í™˜"""
        from src.models.correction_log import DistilledInstruction, CorrectionType
        
        # DynamoDBëŠ” ìˆ«ìë¥¼ Decimalë¡œ ì €ì¥
        item = {
            'pk': 'user#decimal-test',
            'sk': 'instruction#dec001',
            'user_id': 'decimal-test',
            'category': 'tone',
            'context_scope': 'email',
            'instruction': 'test instruction',
            'confidence': Decimal('0.85'),  # DynamoDBì—ì„œ ì˜¤ëŠ” Decimal
            'source_correction_ids': ['c1', 'c2'],
            'pattern_description': 'test pattern',
            'version': Decimal('1'),  # ì •ìˆ˜í˜• Decimal
            'is_active': True
        }
        
        dynamodb_table.put_item(Item=item)
        
        response = dynamodb_table.get_item(Key={'pk': 'user#decimal-test', 'sk': 'instruction#dec001'})
        retrieved = response.get('Item', {})
        
        # Pydanticì´ Decimalì„ float/intë¡œ ë³€í™˜í•´ì•¼ í•¨
        instruction = DistilledInstruction(**retrieved)
        
        assert isinstance(instruction.confidence, float)
        assert instruction.confidence == 0.85
        assert isinstance(instruction.version, int)
        assert instruction.version == 1
    
    def test_missing_optional_fields(self, dynamodb_table):
        """ì„ íƒì  í•„ë“œê°€ ì—†ëŠ” ë°ì´í„°ì—ì„œ ëª¨ë¸ ë³µì›"""
        from src.models.correction_log import CorrectionLog, TaskCategory
        
        # ìµœì†Œ í•„ìˆ˜ í•„ë“œë§Œ ìˆëŠ” ë°ì´í„°
        minimal_item = {
            'pk': 'user#minimal',
            'sk': 'correction#minimal',
            'user_id': 'minimal',
            'workflow_id': 'wf-min',
            'node_id': 'n-min',
            'task_category': 'email',
            'original_input': 'min input',
            'agent_output': 'min output',
            'user_correction': 'min correction',
            'edit_distance': 5,
            'correction_time_seconds': 10,
            'node_type': 'llm',
            'workflow_domain': 'test',
            'context_scope': 'global'
            # ì„ íƒì  í•„ë“œë“¤ ìƒëµ: correction_type, extracted_metadata, etc.
        }
        
        dynamodb_table.put_item(Item=minimal_item)
        
        response = dynamodb_table.get_item(Key={'pk': 'user#minimal', 'sk': 'correction#minimal'})
        retrieved = response.get('Item', {})
        
        # ì„ íƒì  í•„ë“œê°€ ì—†ì–´ë„ ëª¨ë¸ ìƒì„± ì„±ê³µ
        log = CorrectionLog(**retrieved)
        
        assert log.user_id == 'minimal'
        assert log.correction_type is None  # ì„ íƒì  í•„ë“œëŠ” None
        assert log.extracted_metadata == {}  # ê¸°ë³¸ê°’


# ============================================================================
# ğŸ§ª ì˜ë„ì  ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ (Invalid Input Rejection)
# ============================================================================
class TestIntentionalFailures:
    """ì˜ëª»ëœ ë°ì´í„° ì…ë ¥ ì‹œ í™•ì‹¤íˆ ì‹¤íŒ¨í•˜ëŠ”ì§€ ê²€ì¦"""
    
    def test_invalid_task_category_raises_error(self):
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” TaskCategory â†’ ValueError"""
        from src.models.correction_log import TaskCategory
        
        with pytest.raises(ValueError):
            TaskCategory("blockchain_nft_metaverse")  # ì—†ëŠ” ê°’
    
    def test_invalid_correction_type_raises_error(self):
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” CorrectionType â†’ ValueError"""
        from src.models.correction_log import CorrectionType
        
        with pytest.raises(ValueError):
            CorrectionType("quantum_correction")  # ì—†ëŠ” ê°’
    
    def test_confidence_out_of_range_raises_error(self):
        """confidence > 1.0 ë˜ëŠ” < 0.0 â†’ ValidationError"""
        from src.models.correction_log import DistilledInstruction, CorrectionType
        
        with pytest.raises(ValidationError):
            DistilledInstruction(
                pk="user#test",
                user_id="test",
                category=CorrectionType.TONE,
                context_scope="email",
                instruction="test",
                confidence=1.5,  # > 1.0 (le=1 ìœ„ë°˜)
                source_correction_ids=["c1"],
                pattern_description="test"
            )
    
    def test_negative_edit_distance_raises_error(self):
        """edit_distance < 0 â†’ ValidationError"""
        from src.models.correction_log import CorrectionLog, TaskCategory
        
        with pytest.raises(ValidationError):
            CorrectionLog(
                pk="user#test",
                user_id="test",
                workflow_id="wf",
                node_id="n",
                task_category=TaskCategory.EMAIL,
                original_input="test",
                agent_output="test",
                user_correction="test",
                edit_distance=-10,  # ge=0 ìœ„ë°˜
                correction_time_seconds=10,
                node_type="llm",
                workflow_domain="test",
                context_scope="global"
            )
    
    def test_invalid_artifact_type_raises_error(self):
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ArtifactType â†’ ValueError"""
        from src.models.task_context import ArtifactType
        
        with pytest.raises(ValueError):
            ArtifactType("hologram_3d")  # ì—†ëŠ” ê°’
